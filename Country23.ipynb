{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f33b65b-9cf5-41f5-9292-6782c0d82c58",
   "metadata": {},
   "source": [
    "# 1. Introduction\n",
    "### 1.1 Client Background and Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f969b3c-46ee-46fd-a519-59b00f331c87",
   "metadata": {},
   "source": [
    "### 1.2 Project Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270b0a34-2284-48f4-b4b5-971503feddb6",
   "metadata": {},
   "source": [
    "# 2. Data Comprehension\n",
    "### 2.1 Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb1f403-e67f-4794-b80d-4104e620bee1",
   "metadata": {},
   "source": [
    "### Data explanation\n",
    "We started with exploring economic, and policy measures and found several that the team felt could give insights congruent to the needs of the client. Below is the indicator name defintion, and dataframe that we will read into the notebook for exploration and manipulation\n",
    "#### Target Variables\n",
    "1. **Gross Domestic Product per capita (df_gdp)**_*[$US/Capita]* - Monetary value of all of the good and services produced within a contries borders - seen as a key indicator of economic health\n",
    "3. **Poverty Score (df_cpi)**_*[%Population]*\n",
    "\n",
    "#### Features\n",
    "Some of the measures below are united nation assessments **Country Policy and Institutional Assessment** which evaluate a country's policy and intitutional framework\n",
    "\n",
    "- **CPIA - Business Regulatory Assessment (df_reg)**_*[Rating 1-6]* - A united nations rating that assesses how conducive a countries policies are for private sector development (e.g. Ease of operating a business, Regulatory framework, Property rights)\n",
    "- **CPIA - Gender Equity (df_gender)**_*[Rating 1-6]* - rating that measures the extent to which a country's policies promote gender equity and empower women\n",
    "- **CPIA - Social Inclusion (df_social)**_*[Rating 1-6]*\n",
    "- **CPIA - Transparency Accountabilty and Corruption (df_tac)**_*[Rating 1-6]*\n",
    "- **CPIA - Public Resource Equity (df_pre)**_*[Rating 1-6]*\n",
    "- **Health expenditures (df_health)**_*[%US/GDP]*\n",
    "- **Trade Exports (df_trade, df_pop)**_*[%US/Population]*\n",
    "- **Trade Imports (df_trade, df_pop)**_*[%US/Population]*\n",
    "- **Ease of Doing Business (df_edb)**_*[Rating 0-100]*\n",
    "- **Income Distribution (df_inc2q, df_inc3q, df_inc4q, df_ind5q, df_incT10)**_*[%Population]*\n",
    "- **Education expenditures (df_edu)**_*[$US/GDP]*\n",
    "- **Secondary education enrollment (df_college)**_*[%Population]*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "91e4b85b-afe0-41ac-bb04-0276981a7eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries for data collection, manipulation, and exploration\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "49d650b2-1cf7-4683-a8bb-ae39df890ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Target Variables\n",
    "df_gdp = pd.read_csv('https://raw.githubusercontent.com/te-ex153/Data/refs/heads/main/GDP_per_cap_PPP.csv')\n",
    "df_pov = pd.read_csv('https://raw.githubusercontent.com/te-ex153/Data/refs/heads/main/Poverty_Pct_Pop.csv')\n",
    "\n",
    "#### CPIA\n",
    "df_edb = pd.read_csv('https://raw.githubusercontent.com/te-ex153/Data/refs/heads/main/Ease_Doing_Business.csv')\n",
    "df_reg = pd.read_csv('https://raw.githubusercontent.com/te-ex153/Data/refs/heads/main/Business_Regulation.csv')\n",
    "df_gender = pd.read_csv('https://raw.githubusercontent.com/te-ex153/Data/refs/heads/main/Gender_Equity.csv')\n",
    "df_pre = pd.read_csv('https://raw.githubusercontent.com/te-ex153/Data/refs/heads/main/Public_Resource_Equity.csv')\n",
    "df_social = pd.read_csv('https://raw.githubusercontent.com/te-ex153/Data/refs/heads/main/Social_Inclusion.csv')\n",
    "df_tac = pd.read_csv('https://raw.githubusercontent.com/te-ex153/Data/refs/heads/main/Transparency_Accountability_Corruption.csv')\n",
    "\n",
    "#### Government Expenditures\n",
    "df_health = pd.read_csv('https://raw.githubusercontent.com/te-ex153/Data/refs/heads/main/Health_Spend.csv')\n",
    "df_edu = pd.read_csv('https://raw.githubusercontent.com/te-ex153/Data/refs/heads/main/Education_Spend.csv')\n",
    "\n",
    "####  Financial\n",
    "df_trade = pd.read_csv('https://raw.githubusercontent.com/te-ex153/Data/refs/heads/main/Trade.csv')\n",
    "df_inc2q = pd.read_csv('https://raw.githubusercontent.com/te-ex153/Data/refs/heads/main/income_2nd_quintile.csv')\n",
    "df_inc3q = pd.read_csv('https://raw.githubusercontent.com/te-ex153/Data/refs/heads/main/income_3rd_quintile.csv')\n",
    "df_inc4q = pd.read_csv('https://raw.githubusercontent.com/te-ex153/Data/refs/heads/main/income_4th_quintile.csv')\n",
    "df_inc5q = pd.read_csv('https://raw.githubusercontent.com/te-ex153/Data/refs/heads/main/income_5th_quintile.csv')\n",
    "df_incT10 = pd.read_csv('https://raw.githubusercontent.com/te-ex153/Data/refs/heads/main/income_highest_10.csv')\n",
    "\n",
    "#### Other\n",
    "df_college = pd.read_csv('https://raw.githubusercontent.com/te-ex153/Data/refs/heads/main/College_Enrollment.csv')\n",
    "df_pop = pd.read_csv('https://raw.githubusercontent.com/te-ex153/Data/refs/heads/main/population2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bae7091-5439-4ee6-ad58-96781fc0bc39",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.1 EDA - Exploratory Data Analysis and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10396be6-5479-4fcb-b42e-2726075e0b28",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2.1.a Data prep for Target variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "6a834cff-7aeb-401e-a0a8-b96e78bf5de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "I know that i want to end up with a master dataframe with a index ordered by country then year\n",
    "and columns of the various features mentioned above along with the three target variables\n",
    "on the end of the table\n",
    "Therefore for every df i will work to that end by\n",
    "1. take an initial look at the data\n",
    "2. address any missing values  - decided to do this after merging\n",
    "3. strip white spaces \n",
    "4. drop any columns and rows that does not contribute to the study\n",
    "5. reorganize standardize feature, level names, etc to merge seamlessly with other dfs moving forward\n",
    "'''\n",
    "##############  GDP Dataframe\n",
    "df_gdp = df_gdp[['Country or Area', 'Year', 'Value']]  ########## Dropped a footnote column\n",
    "df_gdp = df_gdp.applymap(lambda x: x.strip() if isinstance(x, str) else x)  ######### clean white space for all cells in table\n",
    "df_gdp.columns = df_gdp.columns.str.strip()   ########## strip whitespace for the columns\n",
    "df_gdp = df_gdp.rename(columns=str.lower) ######## make columns all lower case\n",
    "df_gdp = df_gdp.rename(columns={'country or area': 'area', 'value': 'gdp'})    ############ change names to accomodate standardization moving forward\n",
    "df_gdp['gdp'] = df_gdp['gdp'].round(2)  ################## round to two decimals\n",
    "df_gdp['area'] = df_gdp['area'].astype(str)\n",
    "#df_gdp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "05074738-9bf9-4377-9bf8-ed8d93f22688",
   "metadata": {},
   "outputs": [],
   "source": [
    "################ Repeat data prep for poverty measure\n",
    "'''\n",
    "df_pov has a makeup similar to df_gdp but it has footer that are not needed\n",
    "starting below row 1011. i will also needed to get rid of footnotes column\n",
    "'''\n",
    "df_pov = df_pov.applymap(lambda x: x.strip() if isinstance(x, str) else x)   ######### strip wp\n",
    "df_pov.columns = df_pov.columns.str.strip()\n",
    "df_pov = df_pov[['Country or Area', 'Year', 'Value']]  ########### drop footnote\n",
    "df_pov = df_pov.rename(columns={'Country or Area': 'Area', 'Value': '%pov'}) ############## rename for std\n",
    "df_pov = df_pov.rename(columns=str.lower)   ############# make all lower case for std\n",
    "df_pov = df_pov.iloc[:1012, :]  ################## get rid of the footer\n",
    "#df_pov"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a212ef5a-03f4-4795-bca5-832a5fc179c4",
   "metadata": {},
   "source": [
    "#### Data prep for UN Assessment related Feature variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "7e78e07c-8972-4427-a407-9b0112637b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "############### Repeat data prep for CPIA variables\n",
    "''' CPIA_BUSINESS REGULATION'''\n",
    "df_reg = df_reg.applymap(lambda x: x.strip() if isinstance(x, str) else x)   ######### strip wp\n",
    "df_reg.columns = df_reg.columns.str.strip()\n",
    "df_reg = df_reg[['Country or Area', 'Year', 'Value']]  ########### drop footnote\n",
    "df_reg = df_reg.rename(columns={'Country or Area': 'Area', 'Value': 'cpia_regulation'}) ############## rename for std\n",
    "df_reg = df_reg.rename(columns=str.lower)   ############# make all lower case for std\n",
    "#df_reg\n",
    "\n",
    "''' CPIA_GENDER EQUITY'''\n",
    "df_gender = df_gender.applymap(lambda x: x.strip() if isinstance(x, str) else x)   ######### strip wp\n",
    "df_gender.columns = df_gender.columns.str.strip()\n",
    "df_gender = df_gender[['Country or Area', 'Year', 'Value']]  ########### drop footnote\n",
    "df_gender = df_gender.rename(columns={'Country or Area': 'Area', 'Value': 'cpia_gender'}) ############## rename for std\n",
    "df_gender = df_gender.rename(columns=str.lower)   ############# make all lower case for std\n",
    "#df_gender\n",
    "\n",
    "''' CPIA_PUBLIC RESOURCE EQUITY'''\n",
    "df_pre = df_pre.applymap(lambda x: x.strip() if isinstance(x, str) else x)   ######### strip wp\n",
    "df_pre.columns = df_pre.columns.str.strip()\n",
    "df_pre = df_pre[['Country or Area', 'Year', 'Value']]  ########### drop footnote\n",
    "df_pre = df_pre.rename(columns={'Country or Area': 'Area', 'Value': 'cpia_resources'}) ############## rename for std\n",
    "df_pre = df_pre.rename(columns=str.lower)   ############# make all lower case for std\n",
    "#df_pre\n",
    "\n",
    "''' CPIA_TRANSPARENCY ACCOUNTABILITY AND CORRUPTON'''\n",
    "df_tac = df_tac.applymap(lambda x: x.strip() if isinstance(x, str) else x)   ######### strip wp\n",
    "df_tac.columns = df_tac.columns.str.strip()\n",
    "df_tac = df_tac[['Country or Area', 'Year', 'Value']]  ########### drop footnote\n",
    "df_tac = df_tac.rename(columns={'Country or Area': 'Area', 'Value': 'cpia_transparency'}) ############## rename for std\n",
    "df_tac = df_tac.rename(columns=str.lower)   ############# make all lower case for std\n",
    "#df_tac\n",
    "\n",
    "''' CPIA_SOCIAL INCLUSION'''\n",
    "df_social = df_social.applymap(lambda x: x.strip() if isinstance(x, str) else x)   ######### strip wp\n",
    "df_social.columns = df_social.columns.str.strip()\n",
    "df_social = df_social[['Country or Area', 'Year', 'Value']]  ########### drop footnote\n",
    "df_social = df_social.rename(columns={'Country or Area': 'Area', 'Value': 'cpia_inclusion'}) ############## rename for std\n",
    "df_social = df_social.rename(columns=str.lower)   ############# make all lower case for std\n",
    "#df_social\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce7a58b-c3d2-41e9-a1fb-26460673cbd0",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Data prep for Feature variables Healthcare, Education, and Business Ease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "3b4bb62f-509e-43fc-bbd1-ba554c889a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "############## repeat data prep for ease of doing business along with govenmental expenditure variables\n",
    "''' EASE OF DOING BUSINESS '''\n",
    "df_edb = df_edb.applymap(lambda x: x.strip() if isinstance(x, str) else x)   ######### strip wp\n",
    "df_edb.columns = df_edb.columns.str.strip()\n",
    "df_edb = df_edb[['Country or Area', 'Year', 'Value']]  ########### drop footnote\n",
    "df_edb = df_edb.rename(columns={'Country or Area': 'Area', 'Value': 'business_ease'}) ############## rename for std\n",
    "df_edb = df_edb.rename(columns=str.lower)   ############# make all lower case for std\n",
    "#df_edb\n",
    "\n",
    "''' GOVERNMENT EXPENDITURES FOR HEALTHCARE '''\n",
    "df_health.columns = df_health.iloc[0]           ########## resets the column to be the first row\n",
    "df_health = df_health[1:].reset_index(drop=True)  \n",
    "df_health = df_health.applymap(lambda x: x.strip() if isinstance(x, str) else x)   ######### strip wp\n",
    "df_health.columns = df_health.columns.str.strip()\n",
    "df_health.columns.values[1] = 'area'  ########## replace a NaN with area\n",
    "df_health = df_health[['area', 'Year', 'Value']]  ########### drop footnote\n",
    "df_health = df_health.rename(columns={'Value': 'healthcare$'}) ############## rename for std\n",
    "df_health = df_health.rename(columns=str.lower)   ############# make all lower case for std\n",
    "#df_health\n",
    "\n",
    "''' GOVERNMENT EXPENDITURES FOR EDUCATION - different column names than other dfs'''\n",
    "df_edu = df_edu.applymap(lambda x: x.strip() if isinstance(x, str) else x)   ######### strip wp\n",
    "df_edu.columns = df_edu.columns.str.strip()\n",
    "df_edu = df_edu[['Reference Area', 'Time Period', 'Observation Value']]  ########### drop footnote\n",
    "df_edu = df_edu.rename(columns={'Reference Area': 'Area', 'Time Period': 'Year', 'Observation Value': 'education$'}) ############## rename for std\n",
    "df_edu = df_edu.rename(columns=str.lower)   ############# make all lower case for std\n",
    "#df_edu\n",
    "\n",
    "''' GOVERNMENT EXPENDITURES FOR EDUCATION - was setup similar to df_edu'''\n",
    "df_college = df_college.applymap(lambda x: x.strip() if isinstance(x, str) else x)   ######### strip wp\n",
    "df_college.columns = df_college.columns.str.strip()\n",
    "df_college = df_college[['Reference Area', 'Time Period', 'Observation Value']]  ########### drop footnote\n",
    "df_college = df_college.rename(columns={'Reference Area': 'Area', 'Time Period': 'Year', 'Observation Value': 'coll_enrollment'}) ############## rename for std\n",
    "df_college = df_college.rename(columns=str.lower)   ############# make all lower case for std\n",
    "#df_college"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a49d1a6-b6c7-4323-886c-0dcf5eb3594c",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Data prep for Income related Feature variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "1e6685cf-5138-4421-85e4-f46b6206a32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### repeat data prep for income distribution\n",
    "''' 2ND QUINTILE OF INCOME DISTRIBUTION'''\n",
    "df_inc2q = df_inc2q.applymap(lambda x: x.strip() if isinstance(x, str) else x)   ######### strip wp\n",
    "df_inc2q.columns = df_inc2q.columns.str.strip()\n",
    "df_inc2q = df_inc2q[['Country or Area', 'Year', 'Value']]  ########### drop footnote\n",
    "df_inc2q = df_inc2q.rename(columns={'Country or Area': 'Area', 'Value': 'income_quintile2'}) ############## rename for std\n",
    "df_inc2q = df_inc2q.rename(columns=str.lower)   ############# make all lower case for std\n",
    "df_inc2q = df_inc2q.iloc[:2007, :] ################## get rid of footer\n",
    "#df_inc2q\n",
    "\n",
    "''' 3RD QUINTILE OF INCOME DISTRIBUTION'''\n",
    "df_inc3q = df_inc3q.applymap(lambda x: x.strip() if isinstance(x, str) else x)   ######### strip wp\n",
    "df_inc3q.columns = df_inc3q.columns.str.strip()\n",
    "df_inc3q = df_inc3q[['Country or Area', 'Year', 'Value']]  ########### drop footnote\n",
    "df_inc3q = df_inc3q.rename(columns={'Country or Area': 'Area', 'Value': 'income_quintile3'}) ############## rename for std\n",
    "df_inc3q = df_inc3q.rename(columns=str.lower)   ############# make all lower case for std\n",
    "df_inc3q = df_inc3q.iloc[:2007, :] ################## get rid of footer\n",
    "#df_inc3q\n",
    "\n",
    "''' 4TH QUINTILE OF INCOME DISTRIBUTION'''\n",
    "df_inc4q = df_inc4q.applymap(lambda x: x.strip() if isinstance(x, str) else x)   ######### strip wp\n",
    "df_inc4q.columns = df_inc4q.columns.str.strip()\n",
    "df_inc4q = df_inc4q[['Country or Area', 'Year', 'Value']]  ########### drop footnote\n",
    "df_inc4q = df_inc4q.rename(columns={'Country or Area': 'Area', 'Value': 'income_quintile4'}) ############## rename for std\n",
    "df_inc4q = df_inc4q.rename(columns=str.lower)   ############# make all lower case for std\n",
    "df_inc4q = df_inc4q.iloc[:2007, :] ################## get rid of footer\n",
    "#df_inc4q\n",
    "\n",
    "''' 5TH QUINTILE OF INCOME DISTRIBUTION'''\n",
    "df_inc5q = df_inc5q.applymap(lambda x: x.strip() if isinstance(x, str) else x)   ######### strip wp\n",
    "df_inc5q.columns = df_inc5q.columns.str.strip()\n",
    "df_inc5q = df_inc5q[['Country or Area', 'Year', 'Value']]  ########### drop footnote\n",
    "df_inc5q = df_inc5q.rename(columns={'Country or Area': 'Area', 'Value': 'income_quintile5'}) ############## rename for std\n",
    "df_inc5q = df_inc5q.rename(columns=str.lower)   ############# make all lower case for std\n",
    "df_inc5q = df_inc5q.iloc[:2007, :] ################## get rid of footer\n",
    "#df_inc5q\n",
    "\n",
    "''' TOP 10 PERCENT OF INCOME DISTRIBUTION'''\n",
    "df_incT10 = df_incT10.applymap(lambda x: x.strip() if isinstance(x, str) else x)   ######### strip wp\n",
    "df_incT10.columns = df_incT10.columns.str.strip()\n",
    "df_incT10 = df_incT10[['Country or Area', 'Year', 'Value']]  ########### drop footnote\n",
    "df_incT10 = df_incT10.rename(columns={'Country or Area': 'Area', 'Value': 'income_top10%'}) ############## rename for std\n",
    "df_incT10 = df_incT10.rename(columns=str.lower)   ############# make all lower case for std\n",
    "df_incT10 = df_incT10.iloc[:2007, :] ################## get rid of footer\n",
    "#df_incT10\n",
    "\n",
    "''' MERGE ALL OF THE SEPERATE INCOME DFS INTO ONE DF'''\n",
    "df_income = pd.merge(df_inc2q, df_inc3q, on=['area', 'year'], how='inner')\n",
    "df_income = pd.merge(df_income, df_inc4q, on=['area', 'year'], how='inner')\n",
    "df_income = pd.merge(df_income, df_inc5q, on=['area', 'year'], how='inner')\n",
    "df_income = pd.merge(df_income, df_incT10, on=['area', 'year'], how='inner')\n",
    "\n",
    "''' CREATE A NEW COLUMN FOR THE MIDDLE 60% AND DIFFERANCE BETWEEN TOP10% AND MIDDLE 60% '''\n",
    "df_income['income_middle60%'] = df_income['income_quintile2'] + df_income['income_quintile3'] + df_income['income_quintile4']  ########### this is attempting to approximate the  size of middle class\n",
    "df_income['income_difference_top-mid60'] = df_income['income_top10%'] - df_income['income_middle60%']   ###################### this is attempting to approximate this gap between the most wealthy and middle\n",
    "#df_income"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b43c28-0588-430f-9999-579fbf3aba0d",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Data prep for Trade related Feature variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "385286b7-4fab-47aa-8089-3f2f24fbd8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''   CREATE A POPULATION TABLE TO LATER CALCULATE TRADE VALUES PER CAPITA'''\n",
    "################# configure population by area, year, poplulation congruent to other dfs\n",
    "df_pop.columns = df_pop.iloc[3]            ################# assign header and reslice appropriate area\n",
    "df_pop = df_pop[4:].reset_index(drop=True)\n",
    "df_pop = df_pop.drop(columns=['Country Code', 'Indicator Name', 'Indicator Code'])   ################## Drop unneeded columns\n",
    "df_pop2 = df_pop.melt(id_vars=['Country Name'], var_name='year', value_name='population')  ################ Use melt function to stack year and pop along side area\n",
    "df_pop2['year'] = df_pop2['year'].astype(int)   \n",
    "df_pop2 = df_pop2.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "df_pop2 = df_pop2.rename(columns={'Country Name': 'area'})\n",
    "df_pop2['population'] = df_pop2['population'] / 1000000   ################### align unit of measure to later create accurate import/ exports per capita\n",
    "#df_pop2\n",
    "\n",
    "'''  CREATE IMPORT AND EXPORT DFS'''\n",
    "df_trade.columns = df_trade.iloc[0]   ################# assign header and reslice appropriate area\n",
    "df_trade = df_trade[1:].reset_index(drop=True)\n",
    "df_trade.columns.values[1] ='area'\n",
    "df_trade = df_trade[['area', 'Year', 'Series', 'Value']]   ########### drop unneeded columns\n",
    "\n",
    "######### IMPORTS\n",
    "df_imports = df_trade[df_trade['Series'].str.contains(r'Imports CIF', na=False, regex=True)]  ############## pull out import related rows for import df\n",
    "df_imports = df_imports.rename(columns={'Value': 'import$'})\n",
    "df_imports = df_imports.rename(columns=str.lower)\n",
    "df_imports = df_imports.drop(columns=['series'])\n",
    "df_imports['import$'] = df_imports['import$'].str.replace(',', '').astype(float)   ########### get rid of commas to make astype float\n",
    "df_imports['year'] = df_imports['year'].astype(int)\n",
    "\n",
    "######## EXPORTS\n",
    "df_exports = df_trade[df_trade['Series'].str.contains(r'Exports FOB', na=False, regex=True)] ############### pull out export related rows for export df\n",
    "df_exports = df_exports.rename(columns={'Value': 'export$'})\n",
    "df_exports = df_exports.rename(columns=str.lower)\n",
    "df_exports = df_exports.drop(columns=['series'])\n",
    "df_exports['export$'] = df_exports['export$'].str.replace(',', '').astype(float)\n",
    "df_exports['year'] = df_exports['year'].astype(int)\n",
    "\n",
    "''' MERGE TRADE DFS WITH POPULATION TO CREATE A TRADE PER CAPITA DF'''\n",
    "df_trade2 = pd.merge(df_imports, df_exports, on=['area', 'year'], how='inner')\n",
    "df_trade2 = pd.merge(df_trade2, df_pop2, on=['area', 'year'], how='inner')\n",
    "\n",
    "df_trade2['import_capita'] = df_trade2['import$'] / df_trade2['population']   ################ create a column for import export per capita\n",
    "df_trade2['export_capita'] = df_trade2['export$'] / df_trade2['population']\n",
    "\n",
    "df_trade2 = df_trade2[['area', 'year', 'import_capita', 'export_capita']]      ############ drop unneeded columns\n",
    "#df_trade2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "3f0dfcc6-a320-42e0-af66-126a90aaa0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Differnences in area names accross the different dataframes were observered. Also,\n",
    "there are names of regions that comprise of countries listed seperately which is a redundancy.\n",
    "A comparision of areas across all study variables is needed to determine which area names\n",
    "to keep for the study\n",
    "'''\n",
    "########### create a unique set of coutry/areas for each df\n",
    "areas_reg = df_reg[['area']].rename(columns={'area':'reg'}).drop_duplicates()  \n",
    "areas_gen = df_gender[['area']].rename(columns={'area':'gen'}).drop_duplicates()\n",
    "areas_pre = df_pre[['area']].rename(columns={'area':'pre'}).drop_duplicates()\n",
    "areas_tac = df_tac[['area']].rename(columns={'area':'tac'}).drop_duplicates()\n",
    "areas_soc = df_social[['area']].rename(columns={'area':'soc'}).drop_duplicates()\n",
    "areas_hea = df_health[['area']].rename(columns={'area': 'hea'}).drop_duplicates()\n",
    "areas_edu = df_edu[['area']].rename(columns={'area': 'edu'}).drop_duplicates()\n",
    "areas_col = df_college[['area']].rename(columns={'area': 'col'}).drop_duplicates()\n",
    "areas_inc = df_income[['area']].rename(columns={'area': 'inc'}).drop_duplicates()\n",
    "areas_tra = df_trade2[['area']].rename(columns={'area': 'tra'}).drop_duplicates()\n",
    "areas_gdp = df_gdp[['area']].rename(columns={'area':'gdp'}).drop_duplicates()\n",
    "areas_pov = df_pov[['area']].rename(columns={'area':'pov'}).drop_duplicates()\n",
    "\n",
    "########## create a master list of all unique areas\n",
    "all_areas = pd.DataFrame({'area': pd.concat([areas_reg['reg'], areas_gen['gen'], areas_pre['pre'], \\\n",
    "                                            areas_tac['tac'], areas_soc['soc'], areas_hea['hea'], \\\n",
    "                                            areas_edu['edu'], areas_col['col'], areas_inc['inc'], \\\n",
    "                                            areas_tra['tra'], areas_gdp['gdp'], areas_pov['pov']]).drop_duplicates()})\n",
    "\n",
    "########### merge all areas with each df alligned\n",
    "compare_areas = all_areas \\\n",
    ".merge(areas_reg, left_on='area', right_on='reg', how='left') \\\n",
    ".merge(areas_gen, left_on='area', right_on='gen', how='left') \\\n",
    ".merge(areas_pre, left_on='area', right_on='pre', how='left') \\\n",
    ".merge(areas_tac, left_on='area', right_on='tac', how='left') \\\n",
    ".merge(areas_soc, left_on='area', right_on='soc', how='left') \\\n",
    ".merge(areas_hea, left_on='area', right_on='hea', how='left') \\\n",
    ".merge(areas_edu, left_on='area', right_on='edu', how='left') \\\n",
    ".merge(areas_col, left_on='area', right_on='col', how='left') \\\n",
    ".merge(areas_inc, left_on='area', right_on='inc', how='left') \\\n",
    ".merge(areas_tra, left_on='area', right_on='tra', how='left') \\\n",
    ".merge(areas_gdp, left_on='area', right_on='gdp', how='left') \\\n",
    ".merge(areas_pov, left_on='area', right_on='pov', how='left')\n",
    "\n",
    "########## get rid of the 'areas' column\n",
    "compare_areas = compare_areas[['reg', 'gen', 'pre', 'tac', 'soc','hea', 'edu', 'col', 'inc', 'tra','gdp', 'pov']]\n",
    "\n",
    "######### save to csv for review\n",
    "compare_areas.to_csv('compare_areas.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717bb0cd-88cc-40c6-8039-fa5c58605961",
   "metadata": {},
   "source": [
    "# 3. Data Preparation\n",
    "- Cleaning\n",
    "- Transformation\n",
    "- Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6e6b90-8257-4e02-bcaa-8c3007b225de",
   "metadata": {},
   "source": [
    "# 4. Model\n",
    "- Model Selection\n",
    "- Training and testing\n",
    "- Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4995feec-f18f-461d-ae1f-785a24e727d9",
   "metadata": {},
   "source": [
    "# 5. Results\n",
    "- Insights\n",
    "- Reccomendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d58834-6ff5-4401-b4a7-659ad4777452",
   "metadata": {},
   "source": [
    "# 6. Conclusion\n",
    "- Recap\n",
    "- Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf2e965-b0e0-4919-8de2-676f8999eea9",
   "metadata": {},
   "source": [
    "# Appendix\n",
    "- additional information visualizations, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ce8bdd-f1a5-4faa-903f-b39ee6c067bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
