{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f40b98af-c60b-4d6f-90e0-503b0eda2b5b",
   "metadata": {},
   "source": [
    "### 1. Import initial libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "99cae5d1-4f1b-444d-a304-7198a2c73340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries for data collection, manipulation, and exploration\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c0e909-676d-4a44-920f-4e2d7b9b9c17",
   "metadata": {},
   "source": [
    "### 2. Import source flat files from github site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "dd34b12f-f83e-4d4e-b892-500c341ea513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target Variables\n",
    "df_gdp = pd.read_csv('https://raw.githubusercontent.com/te-ex153/Data/refs/heads/main/GDP_per_cap_PPP.csv')\n",
    "df_pov = pd.read_csv('https://raw.githubusercontent.com/te-ex153/Data/refs/heads/main/Poverty_Pct_Pop.csv')\n",
    "\n",
    "# CPIA\n",
    "df_edb = pd.read_csv('https://raw.githubusercontent.com/te-ex153/Data/refs/heads/main/Ease_Doing_Business.csv')\n",
    "df_reg = pd.read_csv('https://raw.githubusercontent.com/te-ex153/Data/refs/heads/main/Business_Regulation.csv')\n",
    "df_gender = pd.read_csv('https://raw.githubusercontent.com/te-ex153/Data/refs/heads/main/Gender_Equity.csv')\n",
    "df_pre = pd.read_csv('https://raw.githubusercontent.com/te-ex153/Data/refs/heads/main/Public_Resource_Equity.csv')\n",
    "df_social = pd.read_csv('https://raw.githubusercontent.com/te-ex153/Data/refs/heads/main/Social_Inclusion.csv')\n",
    "df_tac = pd.read_csv('https://raw.githubusercontent.com/te-ex153/Data/refs/heads/main/Transparency_Accountability_Corruption.csv')\n",
    "df_trdp = pd.read_csv('https://raw.githubusercontent.com/te-ex153/Data/refs/heads/main/cpia_trade.csv')\n",
    "\n",
    "# Government Expenditures\n",
    "df_health = pd.read_csv('https://raw.githubusercontent.com/te-ex153/Data/refs/heads/main/Health_Spend.csv')\n",
    "df_edu = pd.read_csv('https://raw.githubusercontent.com/te-ex153/Data/refs/heads/main/Education_Spend.csv')\n",
    "\n",
    "#  Financial\n",
    "df_trdc = pd.read_csv('https://raw.githubusercontent.com/te-ex153/Data/refs/heads/main/Trade2.csv')\n",
    "df_inc2q = pd.read_csv('https://raw.githubusercontent.com/te-ex153/Data/refs/heads/main/income_2nd_quintile.csv')\n",
    "df_inc3q = pd.read_csv('https://raw.githubusercontent.com/te-ex153/Data/refs/heads/main/income_3rd_quintile.csv')\n",
    "df_inc4q = pd.read_csv('https://raw.githubusercontent.com/te-ex153/Data/refs/heads/main/income_4th_quintile.csv')\n",
    "df_inc5q = pd.read_csv('https://raw.githubusercontent.com/te-ex153/Data/refs/heads/main/income_5th_quintile.csv')\n",
    "df_incT10 = pd.read_csv('https://raw.githubusercontent.com/te-ex153/Data/refs/heads/main/income_highest_10.csv')\n",
    "\n",
    "# Other\n",
    "df_college = pd.read_csv('https://raw.githubusercontent.com/te-ex153/Data/refs/heads/main/College_Enrollment.csv')\n",
    "df_pop = pd.read_csv('https://raw.githubusercontent.com/te-ex153/Data/refs/heads/main/population2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2ba51251-5006-48d3-a67a-d04062caef12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>3</th>\n",
       "      <th>Country Name</th>\n",
       "      <th>1960.0</th>\n",
       "      <th>1961.0</th>\n",
       "      <th>1962.0</th>\n",
       "      <th>1963.0</th>\n",
       "      <th>1964.0</th>\n",
       "      <th>1965.0</th>\n",
       "      <th>1966.0</th>\n",
       "      <th>1967.0</th>\n",
       "      <th>1968.0</th>\n",
       "      <th>...</th>\n",
       "      <th>2014.0</th>\n",
       "      <th>2015.0</th>\n",
       "      <th>2016.0</th>\n",
       "      <th>2017.0</th>\n",
       "      <th>2018.0</th>\n",
       "      <th>2019.0</th>\n",
       "      <th>2020.0</th>\n",
       "      <th>2021.0</th>\n",
       "      <th>2022.0</th>\n",
       "      <th>2023.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aruba</td>\n",
       "      <td>54608.0</td>\n",
       "      <td>55811.0</td>\n",
       "      <td>56682.0</td>\n",
       "      <td>57475.0</td>\n",
       "      <td>58178.0</td>\n",
       "      <td>58782.0</td>\n",
       "      <td>59291.0</td>\n",
       "      <td>59522.0</td>\n",
       "      <td>59471.0</td>\n",
       "      <td>...</td>\n",
       "      <td>103594.0</td>\n",
       "      <td>104257.0</td>\n",
       "      <td>104874.0</td>\n",
       "      <td>105439.0</td>\n",
       "      <td>105962.0</td>\n",
       "      <td>106442.0</td>\n",
       "      <td>106585.0</td>\n",
       "      <td>106537.0</td>\n",
       "      <td>106445.0</td>\n",
       "      <td>106277.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Africa Eastern and Southern</td>\n",
       "      <td>130692579.0</td>\n",
       "      <td>134169237.0</td>\n",
       "      <td>137835590.0</td>\n",
       "      <td>141630546.0</td>\n",
       "      <td>145605995.0</td>\n",
       "      <td>149742351.0</td>\n",
       "      <td>153955516.0</td>\n",
       "      <td>158313235.0</td>\n",
       "      <td>162875171.0</td>\n",
       "      <td>...</td>\n",
       "      <td>583651101.0</td>\n",
       "      <td>600008424.0</td>\n",
       "      <td>616377605.0</td>\n",
       "      <td>632746570.0</td>\n",
       "      <td>649757148.0</td>\n",
       "      <td>667242986.0</td>\n",
       "      <td>685112979.0</td>\n",
       "      <td>702977106.0</td>\n",
       "      <td>720859132.0</td>\n",
       "      <td>739108306.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>8622466.0</td>\n",
       "      <td>8790140.0</td>\n",
       "      <td>8969047.0</td>\n",
       "      <td>9157465.0</td>\n",
       "      <td>9355514.0</td>\n",
       "      <td>9565147.0</td>\n",
       "      <td>9783147.0</td>\n",
       "      <td>10010030.0</td>\n",
       "      <td>10247780.0</td>\n",
       "      <td>...</td>\n",
       "      <td>32716210.0</td>\n",
       "      <td>33753499.0</td>\n",
       "      <td>34636207.0</td>\n",
       "      <td>35643418.0</td>\n",
       "      <td>36686784.0</td>\n",
       "      <td>37769499.0</td>\n",
       "      <td>38972230.0</td>\n",
       "      <td>40099462.0</td>\n",
       "      <td>41128771.0</td>\n",
       "      <td>42239854.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Africa Western and Central</td>\n",
       "      <td>97256290.0</td>\n",
       "      <td>99314028.0</td>\n",
       "      <td>101445032.0</td>\n",
       "      <td>103667517.0</td>\n",
       "      <td>105959979.0</td>\n",
       "      <td>108336203.0</td>\n",
       "      <td>110798486.0</td>\n",
       "      <td>113319950.0</td>\n",
       "      <td>115921723.0</td>\n",
       "      <td>...</td>\n",
       "      <td>397855507.0</td>\n",
       "      <td>408690375.0</td>\n",
       "      <td>419778384.0</td>\n",
       "      <td>431138704.0</td>\n",
       "      <td>442646825.0</td>\n",
       "      <td>454306063.0</td>\n",
       "      <td>466189102.0</td>\n",
       "      <td>478185907.0</td>\n",
       "      <td>490330870.0</td>\n",
       "      <td>502789511.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Angola</td>\n",
       "      <td>5357195.0</td>\n",
       "      <td>5441333.0</td>\n",
       "      <td>5521400.0</td>\n",
       "      <td>5599827.0</td>\n",
       "      <td>5673199.0</td>\n",
       "      <td>5736582.0</td>\n",
       "      <td>5787044.0</td>\n",
       "      <td>5827503.0</td>\n",
       "      <td>5868203.0</td>\n",
       "      <td>...</td>\n",
       "      <td>27128337.0</td>\n",
       "      <td>28127721.0</td>\n",
       "      <td>29154746.0</td>\n",
       "      <td>30208628.0</td>\n",
       "      <td>31273533.0</td>\n",
       "      <td>32353588.0</td>\n",
       "      <td>33428486.0</td>\n",
       "      <td>34503774.0</td>\n",
       "      <td>35588987.0</td>\n",
       "      <td>36684202.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Albania</td>\n",
       "      <td>1608800.0</td>\n",
       "      <td>1659800.0</td>\n",
       "      <td>1711319.0</td>\n",
       "      <td>1762621.0</td>\n",
       "      <td>1814135.0</td>\n",
       "      <td>1864791.0</td>\n",
       "      <td>1914573.0</td>\n",
       "      <td>1965598.0</td>\n",
       "      <td>2022272.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2889104.0</td>\n",
       "      <td>2880703.0</td>\n",
       "      <td>2876101.0</td>\n",
       "      <td>2873457.0</td>\n",
       "      <td>2866376.0</td>\n",
       "      <td>2854191.0</td>\n",
       "      <td>2837849.0</td>\n",
       "      <td>2811666.0</td>\n",
       "      <td>2777689.0</td>\n",
       "      <td>2745972.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>9443.0</td>\n",
       "      <td>10216.0</td>\n",
       "      <td>11014.0</td>\n",
       "      <td>11839.0</td>\n",
       "      <td>12690.0</td>\n",
       "      <td>13563.0</td>\n",
       "      <td>14546.0</td>\n",
       "      <td>15745.0</td>\n",
       "      <td>17079.0</td>\n",
       "      <td>...</td>\n",
       "      <td>71621.0</td>\n",
       "      <td>71746.0</td>\n",
       "      <td>72540.0</td>\n",
       "      <td>73837.0</td>\n",
       "      <td>75013.0</td>\n",
       "      <td>76343.0</td>\n",
       "      <td>77700.0</td>\n",
       "      <td>79034.0</td>\n",
       "      <td>79824.0</td>\n",
       "      <td>80088.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Arab World</td>\n",
       "      <td>93359407.0</td>\n",
       "      <td>95760348.0</td>\n",
       "      <td>98268683.0</td>\n",
       "      <td>100892507.0</td>\n",
       "      <td>103618568.0</td>\n",
       "      <td>106444103.0</td>\n",
       "      <td>109394536.0</td>\n",
       "      <td>112499764.0</td>\n",
       "      <td>115729597.0</td>\n",
       "      <td>...</td>\n",
       "      <td>397922915.0</td>\n",
       "      <td>406501999.0</td>\n",
       "      <td>415077960.0</td>\n",
       "      <td>423664839.0</td>\n",
       "      <td>432545676.0</td>\n",
       "      <td>441467739.0</td>\n",
       "      <td>449228296.0</td>\n",
       "      <td>456520777.0</td>\n",
       "      <td>464684914.0</td>\n",
       "      <td>473272080.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "3                 Country Name       1960.0       1961.0       1962.0  \\\n",
       "0                        Aruba      54608.0      55811.0      56682.0   \n",
       "1  Africa Eastern and Southern  130692579.0  134169237.0  137835590.0   \n",
       "2                  Afghanistan    8622466.0    8790140.0    8969047.0   \n",
       "3   Africa Western and Central   97256290.0   99314028.0  101445032.0   \n",
       "4                       Angola    5357195.0    5441333.0    5521400.0   \n",
       "5                      Albania    1608800.0    1659800.0    1711319.0   \n",
       "6                      Andorra       9443.0      10216.0      11014.0   \n",
       "7                   Arab World   93359407.0   95760348.0   98268683.0   \n",
       "\n",
       "3       1963.0       1964.0       1965.0       1966.0       1967.0  \\\n",
       "0      57475.0      58178.0      58782.0      59291.0      59522.0   \n",
       "1  141630546.0  145605995.0  149742351.0  153955516.0  158313235.0   \n",
       "2    9157465.0    9355514.0    9565147.0    9783147.0   10010030.0   \n",
       "3  103667517.0  105959979.0  108336203.0  110798486.0  113319950.0   \n",
       "4    5599827.0    5673199.0    5736582.0    5787044.0    5827503.0   \n",
       "5    1762621.0    1814135.0    1864791.0    1914573.0    1965598.0   \n",
       "6      11839.0      12690.0      13563.0      14546.0      15745.0   \n",
       "7  100892507.0  103618568.0  106444103.0  109394536.0  112499764.0   \n",
       "\n",
       "3       1968.0  ...       2014.0       2015.0       2016.0       2017.0  \\\n",
       "0      59471.0  ...     103594.0     104257.0     104874.0     105439.0   \n",
       "1  162875171.0  ...  583651101.0  600008424.0  616377605.0  632746570.0   \n",
       "2   10247780.0  ...   32716210.0   33753499.0   34636207.0   35643418.0   \n",
       "3  115921723.0  ...  397855507.0  408690375.0  419778384.0  431138704.0   \n",
       "4    5868203.0  ...   27128337.0   28127721.0   29154746.0   30208628.0   \n",
       "5    2022272.0  ...    2889104.0    2880703.0    2876101.0    2873457.0   \n",
       "6      17079.0  ...      71621.0      71746.0      72540.0      73837.0   \n",
       "7  115729597.0  ...  397922915.0  406501999.0  415077960.0  423664839.0   \n",
       "\n",
       "3       2018.0       2019.0       2020.0       2021.0       2022.0  \\\n",
       "0     105962.0     106442.0     106585.0     106537.0     106445.0   \n",
       "1  649757148.0  667242986.0  685112979.0  702977106.0  720859132.0   \n",
       "2   36686784.0   37769499.0   38972230.0   40099462.0   41128771.0   \n",
       "3  442646825.0  454306063.0  466189102.0  478185907.0  490330870.0   \n",
       "4   31273533.0   32353588.0   33428486.0   34503774.0   35588987.0   \n",
       "5    2866376.0    2854191.0    2837849.0    2811666.0    2777689.0   \n",
       "6      75013.0      76343.0      77700.0      79034.0      79824.0   \n",
       "7  432545676.0  441467739.0  449228296.0  456520777.0  464684914.0   \n",
       "\n",
       "3       2023.0  \n",
       "0     106277.0  \n",
       "1  739108306.0  \n",
       "2   42239854.0  \n",
       "3  502789511.0  \n",
       "4   36684202.0  \n",
       "5    2745972.0  \n",
       "6      80088.0  \n",
       "7  473272080.0  \n",
       "\n",
       "[8 rows x 65 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pop.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6d3fd8-25e5-495e-af17-f9edd71f1843",
   "metadata": {},
   "source": [
    "### 3. Clean, reshape, standardize dataframe for target variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7253fbd1-8f5c-4d02-a3e6-ad89e59b3968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 1 - First five rows of the dataframe for GDP after initial cleaning and prep\n",
      "          area  year      gdp\n",
      "0  Afghanistan  2021  1673.96\n",
      "1  Afghanistan  2020  2078.60\n",
      "2  Afghanistan  2019  2168.13\n",
      "3  Afghanistan  2018  2110.24\n",
      "4  Afghanistan  2017  2096.09\n",
      "7728 Rows , 3 Columns \n",
      "\n",
      "GDP records from the years 1990 to 2022 \n",
      "\n",
      "Table 2 - First five rows of the dataframe for %Poverty after initial cleaning and prep\n",
      "          area  year  %pov\n",
      "0  Afghanistan  2016  54.5\n",
      "1  Afghanistan  2011  38.3\n",
      "2  Afghanistan  2007  33.7\n",
      "3      Albania  2020  22.0\n",
      "4      Albania  2019  21.8\n",
      "1012 Rows , 3 Columns \n",
      "\n",
      "Poverty records from the years 2000 to 2022\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "GDP Dataframe\n",
    "'''\n",
    "# Dropped a footnote column\n",
    "df_gdp = df_gdp[['Country or Area', 'Year', 'Value']]\n",
    "\n",
    "# Clean white space for cells, columns and make lower case\n",
    "df_gdp = df_gdp.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "df_gdp.columns = df_gdp.columns.str.strip().str.lower()\n",
    "\n",
    "# Rename column names for standardization across dfs\n",
    "df_gdp = df_gdp.rename(columns={'country or area': 'area', 'value': 'gdp'})    \n",
    "\n",
    "# Round numbers to two decimals, change type to integer\n",
    "df_gdp['gdp'] = df_gdp['gdp'].round(2)\n",
    "df_gdp['area'] = df_gdp['area'].astype(str)\n",
    "\n",
    "\n",
    "print('Table 1 - First five rows of the dataframe for GDP after initial cleaning and prep')\n",
    "print(df_gdp.head())\n",
    "print(df_gdp.shape[0], 'Rows ,',df_gdp.shape[1], 'Columns','\\n')\n",
    "print(f\"GDP records from the years {min(df_gdp['year'])} to {max(df_gdp['year'])}\",'\\n')\n",
    "'''\n",
    "Poverty Dataframe\n",
    "has a makeup similar to df_gdp but it has a footer thats not informative\n",
    "starting below row 1011. also need to get rid of the footnotes column\n",
    "'''\n",
    "# Clean white space for cells, columns and make lower case\n",
    "df_pov = df_pov.applymap(lambda x: x.strip() if isinstance(x, str) else x)   \n",
    "df_pov.columns = df_pov.columns.str.strip().str.lower()\n",
    "\n",
    "# Drop non-informative columns\n",
    "df_pov = df_pov[['country or area', 'year', 'value']] \n",
    "\n",
    "# Rename column names for standardization across dfs, then make lower case\n",
    "df_pov = df_pov.rename(columns={'country or area': 'area', 'value': '%pov'}) \n",
    "\n",
    "# Remove footer\n",
    "df_pov = df_pov.iloc[:1012, :]  \n",
    "\n",
    "# Convert year into an integer\n",
    "df_pov['year'] = df_pov['year'].astype(int)\n",
    "\n",
    "print('Table 2 - First five rows of the dataframe for %Poverty after initial cleaning and prep')\n",
    "print(df_pov.head())\n",
    "print(df_pov.shape[0], 'Rows ,',df_pov.shape[1], 'Columns','\\n')\n",
    "print(f\"Poverty records from the years {min(df_pov['year'])} to {max(df_pov['year'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b351f18-2e64-40b3-8ad6-d23b199e2187",
   "metadata": {},
   "source": [
    "### 4. Clean, reshape, and standardize dataframe for CPIA related variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "789895f1-0ba4-4533-99d5-5fe9f5f157ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 3 - First five rows of the dataframe for cpia_regulatory after initial cleaning and prep\n",
      "          area  year  cpia_regulation\n",
      "0  Afghanistan  2022              2.0\n",
      "1  Afghanistan  2020              2.0\n",
      "2  Afghanistan  2019              2.0\n",
      "3  Afghanistan  2018              2.0\n",
      "4  Afghanistan  2017              2.0\n",
      "2125 Rows , 3 Columns\n",
      "Table 4 - First five rows of the dataframe for cpia_gender after initial cleaning and prep\n",
      "          area  year  cpia_gender\n",
      "0  Afghanistan  2022          1.0\n",
      "1  Afghanistan  2020          1.5\n",
      "2  Afghanistan  2019          1.5\n",
      "3  Afghanistan  2018          1.5\n",
      "4  Afghanistan  2017          1.5\n",
      "2125 Rows , 3 Columns\n",
      "Table 5 - First five rows of the dataframe for cpia_pre after initial cleaning and prep\n",
      "          area  year  cpia_resources\n",
      "0  Afghanistan  2022             2.0\n",
      "1  Afghanistan  2020             3.5\n",
      "2  Afghanistan  2019             3.5\n",
      "3  Afghanistan  2018             3.0\n",
      "4  Afghanistan  2017             3.0\n",
      "2125 Rows , 3 Columns\n",
      "Table 6 - First five rows of the dataframe for cpia_tac after initial cleaning and prep\n",
      "          area  year  cpia_transparency\n",
      "0  Afghanistan  2022                1.0\n",
      "1  Afghanistan  2020                2.0\n",
      "2  Afghanistan  2019                2.0\n",
      "3  Afghanistan  2018                2.0\n",
      "4  Afghanistan  2017                2.0\n",
      "2125 Rows , 3 Columns\n",
      "Table 7 - First five rows of the dataframe for cpia_social after initial cleaning and prep\n",
      "          area  year  cpia_inclusion\n",
      "0  Afghanistan  2022             1.7\n",
      "1  Afghanistan  2020             2.7\n",
      "2  Afghanistan  2019             2.7\n",
      "3  Afghanistan  2018             2.6\n",
      "4  Afghanistan  2017             2.6\n",
      "2120 Rows , 3 Columns\n",
      "Table 8 - First five rows of the dataframe for cpia_social after initial cleaning and prep\n",
      "          area  year  cpia_trade\n",
      "0  Afghanistan  2023         3.0\n",
      "1  Afghanistan  2022         3.0\n",
      "2  Afghanistan  2020         3.5\n",
      "3  Afghanistan  2019         3.5\n",
      "4  Afghanistan  2018         3.5\n",
      "2240 Rows , 3 Columns \n",
      "\n",
      "All CPIA records from the years 2005 to 2023\n"
     ]
    }
   ],
   "source": [
    "''' CPIA_BUSINESS REGULATION'''\n",
    "# Strip whitespace in table cells, columns and make lower case\n",
    "df_reg = df_reg.applymap(lambda x: x.strip() if isinstance(x, str) else x)   \n",
    "df_reg.columns = df_reg.columns.str.strip().str.lower()\n",
    "\n",
    "# Drop footnote column\n",
    "df_reg = df_reg[['country or area', 'year', 'value']]  \n",
    "\n",
    "# Rename column names for standardization across dfs\n",
    "df_reg = df_reg.rename(columns={'country or area': 'area', 'value': 'cpia_regulation'}) \n",
    "\n",
    "print('Table 3 - First five rows of the dataframe for cpia_regulatory after initial cleaning and prep')\n",
    "print(df_reg.head())\n",
    "print(df_reg.shape[0], 'Rows ,',df_reg.shape[1], 'Columns')\n",
    "\n",
    "''' CPIA_GENDER EQUITY'''\n",
    "# Strip whitespace in table cells, then for each column\n",
    "df_gender = df_gender.applymap(lambda x: x.strip() if isinstance(x, str) else x)   \n",
    "df_gender.columns = df_gender.columns.str.strip().str.lower()\n",
    "\n",
    "# Drop footnote column\n",
    "df_gender = df_gender[['country or area', 'year', 'value']]  \n",
    "\n",
    "# Rename column names for standardization across dfs\n",
    "df_gender = df_gender.rename(columns={'country or area': 'area', 'value': 'cpia_gender'}) \n",
    "\n",
    "\n",
    "print('Table 4 - First five rows of the dataframe for cpia_gender after initial cleaning and prep')\n",
    "print(df_gender.head())\n",
    "print(df_gender.shape[0], 'Rows ,',df_gender.shape[1], 'Columns')\n",
    "\n",
    "''' CPIA_PUBLIC RESOURCE EQUITY'''\n",
    "\n",
    "# Strip whitespace in table cells, then for each column\n",
    "df_pre = df_pre.applymap(lambda x: x.strip() if isinstance(x, str) else x) \n",
    "df_pre.columns = df_pre.columns.str.strip().str.lower()\n",
    "\n",
    "# Drop footnote column\n",
    "df_pre = df_pre[['country or area', 'year', 'value']]\n",
    "\n",
    "# Rename column names for standardization across dfs\n",
    "df_pre = df_pre.rename(columns={'country or area': 'area', 'value': 'cpia_resources'})\n",
    "\n",
    "print('Table 5 - First five rows of the dataframe for cpia_pre after initial cleaning and prep')\n",
    "print(df_pre.head())\n",
    "print(df_pre.shape[0], 'Rows ,',df_pre.shape[1], 'Columns')\n",
    "\n",
    "''' CPIA_TRANSPARENCY ACCOUNTABILITY AND CORRUPTON'''\n",
    "\n",
    "# Strip whitespace in table cells, then for each column\n",
    "df_tac = df_tac.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "df_tac.columns = df_tac.columns.str.strip().str.lower()\n",
    "\n",
    "# Drop footnote column\n",
    "df_tac = df_tac[['country or area', 'year', 'value']] \n",
    "\n",
    "# Rename column names for standardization across dfs\n",
    "df_tac = df_tac.rename(columns={'country or area': 'area', 'value': 'cpia_transparency'}) #### rename for standardization\n",
    "\n",
    "\n",
    "print('Table 6 - First five rows of the dataframe for cpia_tac after initial cleaning and prep')\n",
    "print(df_tac.head())\n",
    "print(df_tac.shape[0], 'Rows ,',df_tac.shape[1], 'Columns')\n",
    "\n",
    "''' CPIA_SOCIAL INCLUSION'''\n",
    "\n",
    "# Strip whitespace in table cells, then for each column\n",
    "df_social = df_social.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "df_social.columns = df_social.columns.str.strip().str.lower()\n",
    "\n",
    "# Drop footnote column\n",
    "df_social = df_social[['country or area', 'year', 'value']]  \n",
    "\n",
    "# Rename column names for standardization across dfs\n",
    "df_social = df_social.rename(columns={'country or area': 'area', 'value': 'cpia_inclusion'})\n",
    "\n",
    "print('Table 7 - First five rows of the dataframe for cpia_social after initial cleaning and prep')\n",
    "print(df_social.head())\n",
    "print(df_social.shape[0], 'Rows ,',df_social.shape[1], 'Columns')\n",
    "\n",
    "''' CPIA_TRADE POLICY'''\n",
    "\n",
    "# Strip whitespace in table cells, then for each column\n",
    "df_trdp = df_trdp.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "df_trdp.columns = df_trdp.columns.str.strip().str.lower()\n",
    "\n",
    "# Drop footnote column\n",
    "df_trdp = df_trdp[['country or area', 'year', 'value']]  \n",
    "\n",
    "# Rename column names for standardization across dfs\n",
    "df_trdp = df_trdp.rename(columns={'country or area': 'area', 'value': 'cpia_trade'})\n",
    "\n",
    "print('Table 8 - First five rows of the dataframe for cpia_social after initial cleaning and prep')\n",
    "print(df_trdp.head())\n",
    "print(df_trdp.shape[0], 'Rows ,',df_trdp.shape[1], 'Columns','\\n')\n",
    "print(f\"All CPIA records from the years {min(df_trdp['year'])} to {max(df_trdp['year'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d1af20-7a5e-4e21-88c1-2a66792ac52c",
   "metadata": {},
   "source": [
    "### 5. Clean, reshape, and standardize dataframe for ease of doing business variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6884d09a-35db-4279-80db-85b40abb3e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 8 - First five rows of the dataframe for edb after initial cleaning and prep\n",
      "          area  year  business_ease\n",
      "0  Afghanistan  2019       44.06497\n",
      "1  Afghanistan  2018       44.20343\n",
      "2  Afghanistan  2017       37.13062\n",
      "3  Afghanistan  2016       38.93563\n",
      "4  Afghanistan  2015       39.25519\n",
      "1187 Rows , 3 Columns \n",
      "\n",
      "Ease of doing business records from the years 2015 to 2019\n"
     ]
    }
   ],
   "source": [
    "''' EASE OF DOING BUSINESS '''\n",
    "\n",
    "# Strip whitespace in table cells, then for each column\n",
    "df_edb = df_edb.applymap(lambda x: x.strip() if isinstance(x, str) else x)   \n",
    "df_edb.columns = df_edb.columns.str.strip().str.lower()\n",
    "\n",
    "# Drop footnote column\n",
    "df_edb = df_edb[['country or area', 'year', 'value']]\n",
    "\n",
    "# Rename column names for standardization across dfs\n",
    "df_edb = df_edb.rename(columns={'country or area': 'area', 'value': 'business_ease'})\n",
    "\n",
    "print('Table 8 - First five rows of the dataframe for edb after initial cleaning and prep')\n",
    "print(df_edb.head())\n",
    "print(df_edb.shape[0], 'Rows ,',df_edb.shape[1], 'Columns', '\\n')\n",
    "print(f\"Ease of doing business records from the years {min(df_edb['year'])} to {max(df_edb['year'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ec5217-5791-4797-87cc-c60f2f51a3ee",
   "metadata": {},
   "source": [
    "Note: Ease of doing business does not have sufficient records compared to targets or other features so will not be included in further study"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f6e996-5381-4892-8608-ba7eb8d0863e",
   "metadata": {},
   "source": [
    "### 6. Clean, reshape, and standardize dataframe for healthcare expenditure variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fac9e58a-1fed-4ff0-8795-7880a074cf0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 9 - First five rows of the dataframe for health expenditures after initial cleaning and prep\n",
      "0         area  year  healthcare$\n",
      "0  Afghanistan  2005          9.9\n",
      "1  Afghanistan  2010          8.6\n",
      "2  Afghanistan  2015         10.1\n",
      "3  Afghanistan  2019         14.8\n",
      "4  Afghanistan  2020         15.5\n",
      "1132 Rows , 3 Columns \n",
      "\n",
      "Health expenditure ecords from the years 2005 to 2021\n"
     ]
    }
   ],
   "source": [
    "''' GOVERNMENT EXPENDITURES FOR HEALTHCARE '''\n",
    "\n",
    "# Resets the column to be the first row, adjust and reset index\n",
    "df_health.columns = df_health.iloc[0] \n",
    "df_health = df_health[1:].reset_index(drop=True)\n",
    "\n",
    "# Strip whitespace for table cells and columns. Make columns lower case\n",
    "df_health = df_health.applymap(lambda x: x.strip() if isinstance(x, str) else x)   \n",
    "df_health.columns = df_health.columns.str.strip().str.lower()\n",
    "\n",
    "# Replace NaN in the first column to the name 'area'\n",
    "df_health.columns.values[1] = 'area'  \n",
    "\n",
    "# Remove rows if the values in column 'series' do not start with the word 'Current'\n",
    "df_health = df_health[df_health['series'].str.startswith('Current')].reset_index(drop=True)\n",
    "\n",
    "# Drop footnote column\n",
    "df_health = df_health[['area', 'year', 'value']]  \n",
    "\n",
    "# Rename column names for standardization across dfs\n",
    "df_health = df_health.rename(columns={'value': 'healthcare$'}) \n",
    "\n",
    "# Change year data type to integer and healthcare$ to float\n",
    "df_health['year'] = df_health['year'].astype(int)\n",
    "df_health['healthcare$'] = df_health['healthcare$'].astype(float)\n",
    "\n",
    "print('Table 9 - First five rows of the dataframe for health expenditures after initial cleaning and prep')\n",
    "print(df_health.head())\n",
    "print(df_health.shape[0], 'Rows ,',df_health.shape[1], 'Columns', '\\n')\n",
    "print(f\"Health expenditure ecords from the years {min(df_health['year'])} to {max(df_health['year'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db57052b-fbee-48c4-8923-11cadae8f8fd",
   "metadata": {},
   "source": [
    "### 7. Clean, reshape, and standardize dataframe for education expenditure variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1da0b5a3-a4ab-4fd3-b69f-b028df75d485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 10 - First five rows of the dataframe for education expenditures after initial cleaning and prep\n",
      "          area  year  education$\n",
      "0  Afghanistan  2014     4.80435\n",
      "1  Afghanistan  2013     4.54436\n",
      "2  Afghanistan  2012     3.12562\n",
      "3  Afghanistan  2011     4.08791\n",
      "4  Afghanistan  2010     4.51116\n",
      "3195 Rows , 3 Columns \n",
      "\n",
      "Education expenditure records from the years 1975 to 2015\n"
     ]
    }
   ],
   "source": [
    "''' GOVERNMENT EXPENDITURES FOR EDUCATION - different column names from other dfs'''\n",
    "\n",
    "# Strip whitespace for table cell and columns. Make columns lower case\n",
    "df_edu = df_edu.applymap(lambda x: x.strip() if isinstance(x, str) else x) \n",
    "df_edu.columns = df_edu.columns.str.strip().str.lower()\n",
    "\n",
    "# Drop footnote column\n",
    "df_edu = df_edu[['reference area', 'time period', 'observation value']] \n",
    "\n",
    "# Rename column names for standardization across dfs\n",
    "df_edu = df_edu.rename(columns={'reference area': 'area', 'time period': 'year', 'observation value': 'education$'})\n",
    "\n",
    "print('Table 10 - First five rows of the dataframe for education expenditures after initial cleaning and prep')\n",
    "print(df_edu.head())\n",
    "print(df_edu.shape[0], 'Rows ,',df_edu.shape[1], 'Columns', '\\n')\n",
    "print(f\"Education expenditure records from the years {min(df_edu['year'])} to {max(df_edu['year'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2ac02b-2435-4c56-892e-60e8aedf0b85",
   "metadata": {},
   "source": [
    "### 8. Clean, reshape, and standardize dataframe for colledge enrollment variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "dc052da2-ea0c-438a-b693-0b844e0bd81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 11 - First five rows of the dataframe for college enrollment after initial cleaning and prep\n",
      "          area  year  coll_enrollment\n",
      "0  Afghanistan  2014         55.65616\n",
      "1  Afghanistan  2013         56.68866\n",
      "2  Afghanistan  2012         56.67734\n",
      "3  Afghanistan  2011         54.61618\n",
      "4  Afghanistan  2010         53.24683\n",
      "5989 Rows , 3 Columns \n",
      "\n",
      "College enrollment records from the years 1975 to 2015\n"
     ]
    }
   ],
   "source": [
    "''' College Enrollment - was setup similar to df_edu'''\n",
    "\n",
    "# Strip whitespace for table cells and columns. Make columns lower case\n",
    "df_college = df_college.applymap(lambda x: x.strip() if isinstance(x, str) else x)  \n",
    "df_college.columns = df_college.columns.str.strip().str.lower()\n",
    "\n",
    "# Remove rows where values in column 'sex' do not start with 'all'\n",
    "df_college = df_college[df_college['sex'].str.startswith('All')].reset_index(drop=True)\n",
    "\n",
    "# Drop footnote column\n",
    "df_college = df_college[['reference area', 'time period', 'observation value']]\n",
    "\n",
    "# Rename column names for standardization across dfs\n",
    "df_college = df_college.rename(columns={'reference area': 'area', 'time period': 'year', 'observation value': 'coll_enrollment'})\n",
    "\n",
    "print('Table 11 - First five rows of the dataframe for college enrollment after initial cleaning and prep')\n",
    "print(df_college.head())\n",
    "print(df_college.shape[0], 'Rows ,',df_college.shape[1], 'Columns','\\n')\n",
    "print(f\"College enrollment records from the years {min(df_college['year'])} to {max(df_college['year'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed306dc-4009-432e-9707-51ab97336bb6",
   "metadata": {},
   "source": [
    "### 9. Clean, reshape, and standardize dataframe for income distribution variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e510ec54-afc6-44cd-9333-81c04213c651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 12 - First five rows of the dataframe for income after initial cleaning and prep\n",
      "      area  year  income_quintile2  income_quintile3  income_quintile4  \\\n",
      "0  Albania  2020              13.2              17.3              23.0   \n",
      "1  Albania  2019              13.0              17.0              22.7   \n",
      "2  Albania  2018              13.0              17.5              23.3   \n",
      "3  Albania  2017              12.0              16.5              23.3   \n",
      "4  Albania  2016              11.8              16.4              23.2   \n",
      "\n",
      "   income_quintile5  income_top10%  income_middle60%  \\\n",
      "0              38.0           22.8              53.5   \n",
      "1              38.9           23.6              52.7   \n",
      "2              38.2           22.7              53.8   \n",
      "3              40.7           24.6              51.8   \n",
      "4              41.2           25.0              51.4   \n",
      "\n",
      "   income_difference_top-mid60  \n",
      "0                        -30.7  \n",
      "1                        -29.1  \n",
      "2                        -31.1  \n",
      "3                        -27.2  \n",
      "4                        -26.4  \n",
      "2007 Rows , 9 Columns \n",
      "\n",
      "Income related records from the years 1963 and 2022\n"
     ]
    }
   ],
   "source": [
    "''' 2ND QUINTILE OF INCOME DISTRIBUTION'''\n",
    "# Strip whitespace for table cells and columns. Make columns lower case\n",
    "df_inc2q = df_inc2q.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "df_inc2q.columns = df_inc2q.columns.str.strip().str.lower()\n",
    "\n",
    "# Drop footnote column\n",
    "df_inc2q = df_inc2q[['country or area', 'year', 'value']] \n",
    "\n",
    "# Rename column names for standardization across dfs\n",
    "df_inc2q = df_inc2q.rename(columns={'country or area': 'area', 'value': 'income_quintile2'}) #### rename for std\n",
    "\n",
    "# Remove footer information\n",
    "df_inc2q = df_inc2q.iloc[:2007, :]\n",
    "#df_inc2q\n",
    "\n",
    "''' 3RD QUINTILE OF INCOME DISTRIBUTION'''\n",
    "\n",
    "# Strip whitespace for table cells and columns. Make columns lower case\n",
    "df_inc3q = df_inc3q.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "df_inc3q.columns = df_inc3q.columns.str.strip().str.lower()\n",
    "\n",
    "# Drop footnote column\n",
    "df_inc3q = df_inc3q[['country or area', 'year', 'value']] \n",
    "\n",
    "# Rename column names for standardization across dfs\n",
    "df_inc3q = df_inc3q.rename(columns={'country or area': 'area', 'value': 'income_quintile3'})\n",
    "\n",
    "# Remove footer information\n",
    "df_inc3q = df_inc3q.iloc[:2007, :]\n",
    "#df_inc3q\n",
    "\n",
    "''' 4TH QUINTILE OF INCOME DISTRIBUTION'''\n",
    "\n",
    "# Strip whitespace for table cells and columns. Make columns lower case\n",
    "df_inc4q = df_inc4q.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "df_inc4q.columns = df_inc4q.columns.str.strip().str.lower()\n",
    "\n",
    "# Drop footnote column\n",
    "df_inc4q = df_inc4q[['country or area', 'year', 'value']] \n",
    "\n",
    "# Rename column names for standardization across dfs\n",
    "df_inc4q = df_inc4q.rename(columns={'country or area': 'area', 'value': 'income_quintile4'})\n",
    "\n",
    "# Remove footer information\n",
    "df_inc4q = df_inc4q.iloc[:2007, :]\n",
    "#df_inc4q\n",
    "\n",
    "''' 5TH QUINTILE OF INCOME DISTRIBUTION'''\n",
    "\n",
    "# Strip whitespace for table cells and columns. Make columns lower case\n",
    "df_inc5q = df_inc5q.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "df_inc5q.columns = df_inc5q.columns.str.strip().str.lower()\n",
    "\n",
    "# Drop footnote column\n",
    "df_inc5q = df_inc5q[['country or area', 'year', 'value']]\n",
    "\n",
    "# Rename column names for standardization across dfs\n",
    "df_inc5q = df_inc5q.rename(columns={'country or area': 'area', 'value': 'income_quintile5'})\n",
    "\n",
    "# Remove footer information\n",
    "df_inc5q = df_inc5q.iloc[:2007, :] \n",
    "#df_inc5q\n",
    "\n",
    "''' TOP 10 PERCENT OF INCOME DISTRIBUTION'''\n",
    "\n",
    "# Strip whitespace for table cells and columns. Make columns lower case\n",
    "df_incT10 = df_incT10.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "df_incT10.columns = df_incT10.columns.str.strip().str.lower()\n",
    "\n",
    "# Drop footnote column\n",
    "df_incT10 = df_incT10[['country or area', 'year', 'value']]\n",
    "df_incT10 = df_incT10.rename(columns={'country or area': 'area', 'value': 'income_top10%'}) #### rename for std\n",
    "\n",
    "# Remove footer information\n",
    "df_incT10 = df_incT10.iloc[:2007, :] \n",
    "#df_incT10\n",
    "\n",
    "''' MERGE ALL OF THE SEPERATE INCOME DFS INTO ONE DF'''\n",
    "df_income = pd.merge(df_inc2q, df_inc3q, on=['area', 'year'], how='inner')\n",
    "df_income = pd.merge(df_income, df_inc4q, on=['area', 'year'], how='inner')\n",
    "df_income = pd.merge(df_income, df_inc5q, on=['area', 'year'], how='inner')\n",
    "df_income = pd.merge(df_income, df_incT10, on=['area', 'year'], how='inner')\n",
    "\n",
    "''' CREATE A NEW COLUMN FOR THE MIDDLE 60% AND DIFFERANCE BETWEEN TOP10% AND MIDDLE 60% '''\n",
    "df_income['income_middle60%'] = df_income['income_quintile2'] + df_income['income_quintile3'] + df_income['income_quintile4']  #### this is attempting to approximate the  size of middle class\n",
    "df_income['income_difference_top-mid60'] = df_income['income_top10%'] - df_income['income_middle60%']   #### this is attempting to approximate this gap between the most wealthy and middle\n",
    "df_income['year'] = df_income['year'].astype(int)\n",
    "#df_income\n",
    "\n",
    "print('Table 12 - First five rows of the dataframe for income after initial cleaning and prep')\n",
    "print(df_income.head())\n",
    "print(df_income.shape[0], 'Rows ,',df_income.shape[1], 'Columns','\\n')\n",
    "print(f\"Income related records from the years {min(df_income['year'])} and {max(df_income['year'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "927e2099-b18d-48ff-834d-922b0ff85ae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country or Area</th>\n",
       "      <th>Year</th>\n",
       "      <th>Commodity</th>\n",
       "      <th>Flow</th>\n",
       "      <th>Trade (USD)</th>\n",
       "      <th>Weight (kg)</th>\n",
       "      <th>Quantity Name</th>\n",
       "      <th>Quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2019</td>\n",
       "      <td>All Commodities</td>\n",
       "      <td>Export</td>\n",
       "      <td>8.704885e+08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No Quantity</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2019</td>\n",
       "      <td>All Commodities</td>\n",
       "      <td>Import</td>\n",
       "      <td>8.568014e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No Quantity</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2019</td>\n",
       "      <td>All Commodities</td>\n",
       "      <td>Re-Export</td>\n",
       "      <td>6.655197e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No Quantity</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2018</td>\n",
       "      <td>All Commodities</td>\n",
       "      <td>Import</td>\n",
       "      <td>7.406590e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No Quantity</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2018</td>\n",
       "      <td>All Commodities</td>\n",
       "      <td>Re-Export</td>\n",
       "      <td>9.263097e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No Quantity</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Country or Area  Year        Commodity       Flow   Trade (USD)  \\\n",
       "0     Afghanistan  2019  All Commodities     Export  8.704885e+08   \n",
       "1     Afghanistan  2019  All Commodities     Import  8.568014e+09   \n",
       "2     Afghanistan  2019  All Commodities  Re-Export  6.655197e+06   \n",
       "3     Afghanistan  2018  All Commodities     Import  7.406590e+09   \n",
       "4     Afghanistan  2018  All Commodities  Re-Export  9.263097e+06   \n",
       "\n",
       "   Weight (kg) Quantity Name  Quantity  \n",
       "0          NaN   No Quantity       NaN  \n",
       "1          NaN   No Quantity       NaN  \n",
       "2          NaN   No Quantity       NaN  \n",
       "3          NaN   No Quantity       NaN  \n",
       "4          NaN   No Quantity       NaN  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trdc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08ce9fd-8c52-43d4-b7a9-6f93180ffdc1",
   "metadata": {},
   "source": [
    "### 10. Clean, reshape, standardize dataframe for trade related variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3457c01-fa09-46c3-a3ae-1bc36f7655d5",
   "metadata": {},
   "source": [
    "##### 10.1 Restructuring population dataframe to merge with import and export dataframes for per capita tranformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b9309f72-ea49-4902-9e0b-02dabdfa4b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              area  year   population\n",
      "0                            Aruba  1960      54608.0\n",
      "1      Africa Eastern and Southern  1960  130692579.0\n",
      "2                      Afghanistan  1960    8622466.0\n",
      "3       Africa Western and Central  1960   97256290.0\n",
      "4                           Angola  1960    5357195.0\n",
      "...                            ...   ...          ...\n",
      "17019                       Kosovo  2023    1756374.0\n",
      "17020                  Yemen, Rep.  2023   34449825.0\n",
      "17021                 South Africa  2023   60414495.0\n",
      "17022                       Zambia  2023   20569737.0\n",
      "17023                     Zimbabwe  2023   16665409.0\n",
      "\n",
      "[17024 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "'''   CREATE A POPULATION TABLE TO LATER CALCULATE TRADE VALUES PER CAPITA'''\n",
    "# Assign fourth row of the df to df.columns and reassign remaining cells \n",
    "df_pop.columns = df_pop.iloc[3]           \n",
    "df_pop = df_pop[4:].reset_index(drop=True)\n",
    "\n",
    "# Remove non-informative columns\n",
    "df_pop = df_pop.drop(columns=['Country Code', 'Indicator Name', 'Indicator Code']) \n",
    "\n",
    "# Use melt function to restructure year and population from long form to a tidy formation\n",
    "df_pop2 = df_pop.melt(id_vars=['Country Name'], var_name='year', value_name='population')  \n",
    "\n",
    "# change year data type to integer\n",
    "df_pop2['year'] = df_pop2['year'].astype(int) \n",
    "\n",
    "# Strip whitespace for table cells\n",
    "df_pop2 = df_pop2.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "\n",
    "# Rename column names for standardization across dfs\n",
    "df_pop2 = df_pop2.rename(columns={'Country Name': 'area'})\n",
    "print(df_pop2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72ddb51-bdc2-40fe-af14-21eefe312379",
   "metadata": {},
   "source": [
    "##### 10.2 Create and wrangle import and export dataframes from trade commodities dataframe (merge with population df, and create per capita values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7e6fd5fd-9cbb-4f6c-83cd-256dc1e21397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 13 - First five rows of the dataframe for trade after initial cleaning and prep\n",
      "          area  year  comm_import_capita  comm_export_capita\n",
      "0  Afghanistan  2019          226.850080           23.047394\n",
      "1  Afghanistan  2018          201.887152           24.109622\n",
      "2  Afghanistan  2017          218.626623           23.340264\n",
      "3  Afghanistan  2016          188.650576           17.220573\n",
      "4  Afghanistan  2015          228.801910           16.928762\n",
      "4014 Rows , 4 Columns \n",
      "\n",
      "Trade related records from the years 1988 and 2023\n"
     ]
    }
   ],
   "source": [
    "'''  CREATE IMPORT AND EXPORT DATAFRAMES'''\n",
    "\n",
    "'''EXPORTS'''\n",
    "df_trdc.tail(20)\n",
    "\n",
    "# Extract records that relate to annual export values only\n",
    "df_exp = df_trdc[df_trdc['Flow'].str.startswith('Export', na=False)]\n",
    "\n",
    "# Remove non-informative columns\n",
    "df_exp = df_exp[['Country or Area', 'Year', 'Trade (USD)']]\n",
    "\n",
    "# Strip whitespace for table cells and columns. Make columns lower case\n",
    "df_exp = df_exp.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "df_exp.columns = df_exp.columns.str.strip().str.lower()\n",
    "\n",
    "# Rename column names for standardization across dfs\n",
    "df_exp = df_exp.rename(columns={'country or area': 'area', 'trade (usd)': 'comm_export$'})\n",
    "\n",
    "'''IMPORTS'''\n",
    "# Extract records that relate to annual import values only\n",
    "df_imp = df_trdc[df_trdc['Flow'].str.startswith('Import', na=False)]\n",
    "\n",
    "# Remove non-informative columns\n",
    "df_imp = df_imp[['Country or Area', 'Year', 'Trade (USD)']]\n",
    "\n",
    "# Strip whitespace for table cells and columns. Make columns lower case\n",
    "df_imp = df_imp.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "df_imp.columns = df_imp.columns.str.strip().str.lower()\n",
    "\n",
    "# Rename column names for standardization across dfs\n",
    "df_imp = df_imp.rename(columns={'country or area': 'area', 'trade (usd)': 'comm_import$'})\n",
    "\n",
    "''' MERGE TRADE DATAFRAMES WITH POPULATION AND CREATE A TRADE PER CAPITA DATAFRAME'''\n",
    "df_trade = pd.merge(df_imp, df_exp, on=['area', 'year'], how='inner')\n",
    "df_trade = pd.merge(df_trade, df_pop2, on=['area', 'year'], how='inner')\n",
    "\n",
    "# Conversion of values to per capita values\n",
    "df_trade['comm_import_capita'] = df_trade['comm_import$'] / df_trade['population'] \n",
    "df_trade['comm_export_capita'] = df_trade['comm_export$'] / df_trade['population']\n",
    "\n",
    "# Drop non-informative columns\n",
    "df_trade = df_trade[['area', 'year', 'comm_import_capita', 'comm_export_capita']] \n",
    "\n",
    "print('Table 13 - First five rows of the dataframe for trade after initial cleaning and prep')\n",
    "print(df_trade.head())\n",
    "print(df_trade.shape[0], 'Rows ,',df_trade.shape[1], 'Columns', '\\n')\n",
    "print(f\"Trade related records from the years {min(df_trade['year'])} and {max(df_trade['year'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb449b3-f531-44d8-9f29-fc6c94d55a61",
   "metadata": {},
   "source": [
    "### 11. Evaluating issues with in the area category (multiple naming conventions, non-area related categories, aggrated areas vs countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e006b1a9-6589-4e07-ac9a-a676c49ac8fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique area names prior to standardizing naming convention: 320\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Create a unique set of coutry/areas for each df. The idea here need to see what dfs contains what\n",
    "area related information and standardize that information across dfs prior to merging them\n",
    "'''\n",
    "# Create unique area names for each df\n",
    "areas_reg = df_reg[['area']].rename(columns={'area':'reg'}).drop_duplicates()  \n",
    "areas_gen = df_gender[['area']].rename(columns={'area':'gen'}).drop_duplicates()\n",
    "areas_pre = df_pre[['area']].rename(columns={'area':'pre'}).drop_duplicates()\n",
    "areas_tac = df_tac[['area']].rename(columns={'area':'tac'}).drop_duplicates()\n",
    "areas_soc = df_social[['area']].rename(columns={'area':'soc'}).drop_duplicates()\n",
    "areas_trp = df_trdp[['area']].rename(columns={'area': 'trp'}).drop_duplicates()\n",
    "areas_hea = df_health[['area']].rename(columns={'area': 'hea'}).drop_duplicates()\n",
    "areas_edu = df_edu[['area']].rename(columns={'area': 'edu'}).drop_duplicates()\n",
    "areas_col = df_college[['area']].rename(columns={'area': 'col'}).drop_duplicates()\n",
    "areas_inc = df_income[['area']].rename(columns={'area': 'inc'}).drop_duplicates()\n",
    "areas_tra = df_trade[['area']].rename(columns={'area': 'tra'}).drop_duplicates()\n",
    "areas_gdp = df_gdp[['area']].rename(columns={'area':'gdp'}).drop_duplicates()\n",
    "areas_pov = df_pov[['area']].rename(columns={'area':'pov'}).drop_duplicates()\n",
    "\n",
    "# Create a master list of all unique area names, by stacking the different df area names from above then dropping duplicates\n",
    "all_areas = pd.DataFrame({'area': pd.concat([areas_reg['reg'], areas_gen['gen'], areas_pre['pre'], \\\n",
    "                                            areas_tac['tac'], areas_soc['soc'], areas_trp['trp'], areas_hea['hea'], \\\n",
    "                                            areas_edu['edu'], areas_col['col'], areas_inc['inc'], \\\n",
    "                                            areas_tra['tra'], areas_gdp['gdp'], areas_pov['pov']]).drop_duplicates()})\n",
    "'''\n",
    "Left merge all area names from different variable dfs to the master area name list. We explictly tell the merge() function\n",
    "what two columns to merge since we change the 'area' column in the original df to variable specific name such as 'reg'\n",
    "'''\n",
    "compare_areas = all_areas \\\n",
    ".merge(areas_reg, left_on='area', right_on='reg', how='left') \\\n",
    ".merge(areas_gen, left_on='area', right_on='gen', how='left') \\\n",
    ".merge(areas_pre, left_on='area', right_on='pre', how='left') \\\n",
    ".merge(areas_tac, left_on='area', right_on='tac', how='left') \\\n",
    ".merge(areas_soc, left_on='area', right_on='soc', how='left') \\\n",
    ".merge(areas_trp, left_on='area', right_on='trp', how='left') \\\n",
    ".merge(areas_hea, left_on='area', right_on='hea', how='left') \\\n",
    ".merge(areas_edu, left_on='area', right_on='edu', how='left') \\\n",
    ".merge(areas_col, left_on='area', right_on='col', how='left') \\\n",
    ".merge(areas_inc, left_on='area', right_on='inc', how='left') \\\n",
    ".merge(areas_tra, left_on='area', right_on='tra', how='left') \\\n",
    ".merge(areas_gdp, left_on='area', right_on='gdp', how='left') \\\n",
    ".merge(areas_pov, left_on='area', right_on='pov', how='left')\n",
    "\n",
    "# Get rid of the 'areas' column\n",
    "compare_areas = compare_areas[['reg', 'gen', 'pre', 'tac', 'soc','trp','hea', 'edu', 'col', 'inc', 'tra','gdp', 'pov']]\n",
    "\n",
    "# Create a column which captures ea rows unique string(area name)\n",
    "compare_areas['unique_name'] = compare_areas.apply(lambda row: row.dropna().iloc[0] if not row.dropna().empty else np.nan, axis=1)\n",
    "\n",
    "# Save to csv for review\n",
    "compare_areas.to_csv('compare_areas.csv', index=False)\n",
    "\n",
    "print(f'Number of unique area names prior to standardizing naming convention: {len(compare_areas)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2892038b-5cd9-454b-965e-292f630d4b6c",
   "metadata": {},
   "source": [
    "### 12. Remove duplicate country names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6beff41c-f5fe-4180-8374-0b3507ea78c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique area names after to standardizing naming convention : 295\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Create the re search criteria to find then remove duplicate names\n",
    "regex_dict = {\n",
    "    r'^Bolivia': 'Bolivia', \n",
    "    r'^C.*voire$':'Ivory Coast', \n",
    "    r'^Czech': 'Czech Republic', \n",
    "    r'^Dem.*ongo$': 'D.R. Congo', \n",
    "    r'Hong\\sKong': 'Hong Kong', \n",
    "    r'Iran': 'Iran', \n",
    "    r'Korea': 'Korea', \n",
    "    r'Lao\\sP': 'Lao', \n",
    "    r'^Libya': 'Libya', \n",
    "    r'^Macao': 'Macao', \n",
    "    r'Micronesia': 'Micronesia', \n",
    "    r'Netherlands': 'Netherlands', \n",
    "    r'Russia': 'Russia', \n",
    "    r'^T.*iye$|Turkey': 'Turkiye', \n",
    "    r'^Tanzania': 'Tanzania', \n",
    "    r'United\\sKingdom': 'United Kingdom', \n",
    "    r'United\\sStates': 'United States', \n",
    "    r'Venezuela': 'Venezuela',\n",
    "    r'^S.*Principe$': 'Sao Tome and Principe',\n",
    "    r'^Kyrgyz': 'Kyrgyzstan',\n",
    "    r'Gambia': 'Gambia',\n",
    "    r'^Cura.*ao$': 'Curacao'\n",
    "}\n",
    "\n",
    "# Function to standardize names\n",
    "def standardize_country(name, regex_dict):\n",
    "    for pattern, standard_name in regex_dict.items():\n",
    "        if re.match(pattern, name):\n",
    "            return standard_name\n",
    "    return name\n",
    "\n",
    "\n",
    "# Update the names with the function (confirmed it was working with df['area2'] before rolling to all dfs)\n",
    "df_reg['area'] = df_reg['area'].apply(lambda x: standardize_country(x, regex_dict))\n",
    "df_gender['area'] = df_gender['area'].apply(lambda x: standardize_country(x, regex_dict))\n",
    "df_pre['area'] = df_pre['area'].apply(lambda x: standardize_country(x, regex_dict))\n",
    "df_tac['area'] = df_tac['area'].apply(lambda x: standardize_country(x, regex_dict))\n",
    "df_social['area'] = df_social['area'].apply(lambda x: standardize_country(x, regex_dict))\n",
    "df_trdp['area'] = df_trdp['area'].apply(lambda x: standardize_country(x, regex_dict))\n",
    "df_health['area'] = df_health['area'].apply(lambda x: standardize_country(x, regex_dict))\n",
    "df_edu['area'] = df_edu['area'].apply(lambda x: standardize_country(x, regex_dict))\n",
    "df_college['area'] = df_college['area'].apply(lambda x: standardize_country(x, regex_dict))\n",
    "df_income['area'] = df_income['area'].apply(lambda x: standardize_country(x, regex_dict))\n",
    "df_trade['area'] = df_trade['area'].apply(lambda x: standardize_country(x, regex_dict))\n",
    "df_gdp['area'] = df_gdp['area'].apply(lambda x: standardize_country(x, regex_dict))\n",
    "df_pov['area'] = df_pov['area'].apply(lambda x: standardize_country(x, regex_dict))\n",
    "\n",
    "'''\n",
    "Repeat the section above to observe how standardizing naming convention reduced the \n",
    "number of unique area names, and confirm no more inconsistencies by creating/reviewing \n",
    "compare_areas2\n",
    "'''\n",
    "\n",
    "# Create unique area names for each df\n",
    "areas_reg = df_reg[['area']].rename(columns={'area':'reg'}).drop_duplicates()  \n",
    "areas_gen = df_gender[['area']].rename(columns={'area':'gen'}).drop_duplicates()\n",
    "areas_pre = df_pre[['area']].rename(columns={'area':'pre'}).drop_duplicates()\n",
    "areas_tac = df_tac[['area']].rename(columns={'area':'tac'}).drop_duplicates()\n",
    "areas_soc = df_social[['area']].rename(columns={'area':'soc'}).drop_duplicates()\n",
    "areas_trp = df_trdp[['area']].rename(columns={'area': 'trp'}).drop_duplicates()\n",
    "areas_hea = df_health[['area']].rename(columns={'area': 'hea'}).drop_duplicates()\n",
    "areas_edu = df_edu[['area']].rename(columns={'area': 'edu'}).drop_duplicates()\n",
    "areas_col = df_college[['area']].rename(columns={'area': 'col'}).drop_duplicates()\n",
    "areas_inc = df_income[['area']].rename(columns={'area': 'inc'}).drop_duplicates()\n",
    "areas_tra = df_trade[['area']].rename(columns={'area': 'tra'}).drop_duplicates()\n",
    "areas_gdp = df_gdp[['area']].rename(columns={'area':'gdp'}).drop_duplicates()\n",
    "areas_pov = df_pov[['area']].rename(columns={'area':'pov'}).drop_duplicates()\n",
    "\n",
    "# Create a master list of all unique area names, by stacking the different df area names from above then dropping duplicates\n",
    "all_areas = pd.DataFrame({'area': pd.concat([areas_reg['reg'], areas_gen['gen'], areas_pre['pre'], \\\n",
    "                                            areas_tac['tac'], areas_soc['soc'], areas_trp['trp'], areas_hea['hea'], \\\n",
    "                                            areas_edu['edu'], areas_col['col'], areas_inc['inc'], \\\n",
    "                                            areas_tra['tra'], areas_gdp['gdp'], areas_pov['pov']]).drop_duplicates()})\n",
    "'''\n",
    "Left merge all area names from different variable dfs to the master area name list. We explictly tell the merge() function\n",
    "what two columns to merge since we change the 'area' column in the original df to variable specific name such as 'reg'\n",
    "'''\n",
    "compare_areas2 = all_areas \\\n",
    ".merge(areas_reg, left_on='area', right_on='reg', how='left') \\\n",
    ".merge(areas_gen, left_on='area', right_on='gen', how='left') \\\n",
    ".merge(areas_pre, left_on='area', right_on='pre', how='left') \\\n",
    ".merge(areas_tac, left_on='area', right_on='tac', how='left') \\\n",
    ".merge(areas_soc, left_on='area', right_on='soc', how='left') \\\n",
    ".merge(areas_trp, left_on='area', right_on='trp', how='left') \\\n",
    ".merge(areas_hea, left_on='area', right_on='hea', how='left') \\\n",
    ".merge(areas_edu, left_on='area', right_on='edu', how='left') \\\n",
    ".merge(areas_col, left_on='area', right_on='col', how='left') \\\n",
    ".merge(areas_inc, left_on='area', right_on='inc', how='left') \\\n",
    ".merge(areas_tra, left_on='area', right_on='tra', how='left') \\\n",
    ".merge(areas_gdp, left_on='area', right_on='gdp', how='left') \\\n",
    ".merge(areas_pov, left_on='area', right_on='pov', how='left')\n",
    "\n",
    "\n",
    "# Get rid of the 'areas' column\n",
    "compare_areas2 = compare_areas2[['reg', 'gen', 'pre', 'tac', 'soc','trp','hea', 'edu', 'col', 'inc', 'tra','gdp', 'pov']]\n",
    "\n",
    "# Create a column which captures ea rows unique string(area name)\n",
    "compare_areas2['unique_name'] = compare_areas2.apply(lambda row: row.dropna().iloc[0] if not row.dropna().empty else np.nan, axis=1)\n",
    "# Save to csv for review\n",
    "\n",
    "compare_areas2.to_csv('compare_areas2.csv', index=False)\n",
    "\n",
    "print(f'Number of unique area names after to standardizing naming convention : {len(all_areas)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966d604d-a17c-4d9b-a23a-67e06421d274",
   "metadata": {},
   "source": [
    "### 13. Merge variable dataframes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f059d260-8a38-4e6a-9f4e-1c96c817e301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 14 - First five rows of the Master Dataframe_v1\n",
      "          area  year      gdp  %pov  cpia_regulation  cpia_gender  \\\n",
      "0  Afghanistan  2002   943.12   NaN              NaN          NaN   \n",
      "1  Afghanistan  2003   970.65   NaN              NaN          NaN   \n",
      "2  Afghanistan  2004   971.81   NaN              NaN          NaN   \n",
      "3  Afghanistan  2005  1075.67   NaN              NaN          NaN   \n",
      "4  Afghanistan  2006  1120.89   NaN              2.5          2.0   \n",
      "\n",
      "   cpia_resources  cpia_transparency  cpia_inclusion  cpia_trade  ...  \\\n",
      "0             NaN                NaN             NaN         NaN  ...   \n",
      "1             NaN                NaN             NaN         NaN  ...   \n",
      "2             NaN                NaN             NaN         NaN  ...   \n",
      "3             NaN                NaN             NaN         NaN  ...   \n",
      "4             2.5                2.5             2.3         3.0  ...   \n",
      "\n",
      "   coll_enrollment  income_quintile2  income_quintile3  income_quintile4  \\\n",
      "0              NaN               NaN               NaN               NaN   \n",
      "1         13.31708               NaN               NaN               NaN   \n",
      "2         18.66479               NaN               NaN               NaN   \n",
      "3         19.78370               NaN               NaN               NaN   \n",
      "4         29.93046               NaN               NaN               NaN   \n",
      "\n",
      "   income_quintile5  income_top10%  income_middle60%  \\\n",
      "0               NaN            NaN               NaN   \n",
      "1               NaN            NaN               NaN   \n",
      "2               NaN            NaN               NaN   \n",
      "3               NaN            NaN               NaN   \n",
      "4               NaN            NaN               NaN   \n",
      "\n",
      "   income_difference_top-mid60  comm_import_capita  comm_export_capita  \n",
      "0                          NaN                 NaN                 NaN  \n",
      "1                          NaN                 NaN                 NaN  \n",
      "2                          NaN                 NaN                 NaN  \n",
      "3                          NaN                 NaN                 NaN  \n",
      "4                          NaN                 NaN                 NaN  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "5533 Rows , 22 Columns\n"
     ]
    }
   ],
   "source": [
    "# Merge all of the dfs\n",
    "'''\n",
    "The df_gdp is the most significant df, since wer not interested in any feature that \n",
    "does not measure gdp. Also df_gdp happens to have the widest range in years in \n",
    "which will be truncated. based on this all other dfs will be merged to df_gdp\n",
    "'''\n",
    "df_economy = pd.merge(df_gdp, df_pov, on=['area', 'year'], how='left')\n",
    "df_economy = pd.merge(df_economy, df_reg, on=['area', 'year'], how='left')\n",
    "df_economy = pd.merge(df_economy, df_gender, on=['area', 'year'], how='left')\n",
    "df_economy = pd.merge(df_economy, df_pre, on=['area', 'year'], how='left')\n",
    "df_economy = pd.merge(df_economy, df_tac, on=['area', 'year'], how='left')\n",
    "df_economy = pd.merge(df_economy, df_social, on=['area', 'year'], how='left')\n",
    "df_economy = pd.merge(df_economy, df_trdp, on=['area', 'year'], how='left')\n",
    "df_economy = pd.merge(df_economy, df_health, on=['area', 'year'], how='left')\n",
    "df_economy = pd.merge(df_economy, df_edu, on=['area', 'year'], how='left')\n",
    "df_economy = pd.merge(df_economy, df_college, on=['area', 'year'], how='left')\n",
    "df_economy = pd.merge(df_economy, df_income, on=['area', 'year'], how='left')\n",
    "df_economy = pd.merge(df_economy, df_trade, on=['area', 'year'], how='left')\n",
    "\n",
    "df_economy = df_economy.sort_values(by=['area', 'year']).reset_index(drop=True)\n",
    "\n",
    "# Remove sparse years from dataset\n",
    "'''\n",
    "A review was done of each dataset against the years data was being collected,\n",
    "again giving priority to gdp since that is the primary target variable. The years\n",
    "between 2000 and 2020 give the dataset the densest table vs the feature variables\n",
    "'''\n",
    "df_economy = df_economy[df_economy['year'].between(2000, 2022)].reset_index(drop=True)\n",
    "df_economy.to_csv('df_economy.csv', index=False)\n",
    "\n",
    "print('Table 14 - First five rows of the Master Dataframe_v1')\n",
    "print(df_economy.head())\n",
    "print(df_economy.shape[0], 'Rows ,',df_economy.shape[1], 'Columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871048f1-34ad-4e37-81a4-29b01a0c863a",
   "metadata": {},
   "source": [
    "13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a4f535-bf0a-4551-932d-d41ee3bf249e",
   "metadata": {},
   "source": [
    "### 14. Remove non area related records from table\n",
    "1. Create a df with unique set of country names to evaluate off line\n",
    "2. Read back in the adjusted version of that df add the appropriate Regions as defined by the UN associated with each country\n",
    "3. Create a dictionary to fill in the column 'Region 1' with singularly aggregate groups of countries\n",
    "4. Create a dictionary to fill in the column 'Region 2' with dually aggregated groups of countries\n",
    "5. Create a dictionary where the associated df_names will become a dictionaries to create columns called 'region' and 'un_region' in the master df_economy\n",
    "6. Drop all non-region related, or non-regionally informative records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4d8d0434-4c71-4859-b037-5dd67593e944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download a table of area names to further further evaluate inconsistencies off line\n",
    "area_names = pd.DataFrame({'area': df_economy['area'].unique()})\n",
    "area_names.to_csv('area_names.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c4c5d26d-14e6-416e-a5b2-06c8a5d0c25b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 15 - Dataframe showing area with regional columns to be filled in\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>area</th>\n",
       "      <th>Region 1</th>\n",
       "      <th>Region 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R</td>\n",
       "      <td>Africa Eastern and Southern</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R</td>\n",
       "      <td>Africa Western and Central</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C</td>\n",
       "      <td>Albania</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>C</td>\n",
       "      <td>West Bank and Gaza</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>O</td>\n",
       "      <td>World</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>C</td>\n",
       "      <td>Yemen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>C</td>\n",
       "      <td>Zambia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>C</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>246 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID                         area  Region 1  Region 2\n",
       "0    C                  Afghanistan       NaN       NaN\n",
       "1    R  Africa Eastern and Southern       NaN       NaN\n",
       "2    R   Africa Western and Central       NaN       NaN\n",
       "3    C                      Albania       NaN       NaN\n",
       "4    C                      Algeria       NaN       NaN\n",
       "..  ..                          ...       ...       ...\n",
       "241  C           West Bank and Gaza       NaN       NaN\n",
       "242  O                        World       NaN       NaN\n",
       "243  C                        Yemen       NaN       NaN\n",
       "244  C                       Zambia       NaN       NaN\n",
       "245  C                     Zimbabwe       NaN       NaN\n",
       "\n",
       "[246 rows x 4 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read back in evaluated df for processing\n",
    "df_names = pd.read_csv('https://raw.githubusercontent.com/te-ex153/Data/refs/heads/main/area_names_adj.csv')\n",
    "print('Table 15 - Dataframe showing area with regional columns to be filled in')\n",
    "df_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c6b237e2-3ea9-4f77-93dd-24dbefdef94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 16 - Dataframe showing countries with their associated singular and UN specified regions\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>area</th>\n",
       "      <th>Region 1</th>\n",
       "      <th>Region 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>C</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Europe &amp; Central Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>C</td>\n",
       "      <td>Comoros</td>\n",
       "      <td>Eastern Africa</td>\n",
       "      <td>Africa Eastern and Southern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>C</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Europe &amp; Central Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>C</td>\n",
       "      <td>Kyrgyzstan</td>\n",
       "      <td>Central Asia</td>\n",
       "      <td>Europe &amp; Central Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>C</td>\n",
       "      <td>Maldives</td>\n",
       "      <td>South Asia</td>\n",
       "      <td>South Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>C</td>\n",
       "      <td>Yemen</td>\n",
       "      <td>Middle East</td>\n",
       "      <td>Middle East &amp; North Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>C</td>\n",
       "      <td>Viet Nam</td>\n",
       "      <td>East Asia</td>\n",
       "      <td>East Asia &amp; Pacific</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>C</td>\n",
       "      <td>The Bahamas</td>\n",
       "      <td>Caribbean</td>\n",
       "      <td>Latin America &amp; Caribbean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>C</td>\n",
       "      <td>Belize</td>\n",
       "      <td>Latin America</td>\n",
       "      <td>Latin America &amp; Caribbean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R</td>\n",
       "      <td>Africa Western and Central</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>Africa Western and Central</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>R</td>\n",
       "      <td>Latin America &amp; Caribbean</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>Latin America &amp; Caribbean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>C</td>\n",
       "      <td>Brunei</td>\n",
       "      <td>East Asia</td>\n",
       "      <td>East Asia &amp; Pacific</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>C</td>\n",
       "      <td>Uzbekistan</td>\n",
       "      <td>Central Asia</td>\n",
       "      <td>Europe &amp; Central Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>C</td>\n",
       "      <td>Namibia</td>\n",
       "      <td>Southern Africa</td>\n",
       "      <td>Africa Eastern and Southern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>C</td>\n",
       "      <td>Bhutan</td>\n",
       "      <td>South Asia</td>\n",
       "      <td>South Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>C</td>\n",
       "      <td>Bahrain</td>\n",
       "      <td>Middle East</td>\n",
       "      <td>Middle East &amp; North Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>C</td>\n",
       "      <td>Uganda</td>\n",
       "      <td>Eastern Africa</td>\n",
       "      <td>Africa Eastern and Southern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>C</td>\n",
       "      <td>Sudan</td>\n",
       "      <td>Northern Africa</td>\n",
       "      <td>Middle East &amp; North Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>C</td>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>South Asia</td>\n",
       "      <td>South Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>C</td>\n",
       "      <td>Togo</td>\n",
       "      <td>Western Africa</td>\n",
       "      <td>Africa Western and Central</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>C</td>\n",
       "      <td>Somalia</td>\n",
       "      <td>Eastern Africa</td>\n",
       "      <td>Africa Eastern and Southern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>C</td>\n",
       "      <td>Tanzania</td>\n",
       "      <td>Eastern Africa</td>\n",
       "      <td>Africa Eastern and Southern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>C</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>East Asia</td>\n",
       "      <td>East Asia &amp; Pacific</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>C</td>\n",
       "      <td>Marshall Islands</td>\n",
       "      <td>Pacific</td>\n",
       "      <td>East Asia &amp; Pacific</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>C</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Central Europe</td>\n",
       "      <td>Central Europe and the baltics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>C</td>\n",
       "      <td>Nepal</td>\n",
       "      <td>South Asia</td>\n",
       "      <td>South Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>C</td>\n",
       "      <td>Solomon Islands</td>\n",
       "      <td>Pacific</td>\n",
       "      <td>East Asia &amp; Pacific</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>C</td>\n",
       "      <td>Mauritius</td>\n",
       "      <td>Eastern Africa</td>\n",
       "      <td>Africa Eastern and Southern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>C</td>\n",
       "      <td>Colombia</td>\n",
       "      <td>Latin America</td>\n",
       "      <td>Latin America &amp; Caribbean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>C</td>\n",
       "      <td>Curacao</td>\n",
       "      <td>Caribbean</td>\n",
       "      <td>Latin America &amp; Caribbean</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID                        area         Region 1  \\\n",
       "233  C              United Kingdom           Europe   \n",
       "43   C                     Comoros   Eastern Africa   \n",
       "77   C                     Georgia           Europe   \n",
       "115  C                  Kyrgyzstan     Central Asia   \n",
       "136  C                    Maldives       South Asia   \n",
       "243  C                       Yemen      Middle East   \n",
       "240  C                    Viet Nam        East Asia   \n",
       "219  C                 The Bahamas        Caribbean   \n",
       "19   C                      Belize    Latin America   \n",
       "2    R  Africa Western and Central   Not Applicable   \n",
       "118  R   Latin America & Caribbean   Not Applicable   \n",
       "27   C                      Brunei        East Asia   \n",
       "237  C                  Uzbekistan     Central Asia   \n",
       "154  C                     Namibia  Southern Africa   \n",
       "22   C                      Bhutan       South Asia   \n",
       "14   C                     Bahrain      Middle East   \n",
       "230  C                      Uganda   Eastern Africa   \n",
       "212  C                       Sudan  Northern Africa   \n",
       "205  C                   Sri Lanka       South Asia   \n",
       "222  C                        Togo   Western Africa   \n",
       "199  C                     Somalia   Eastern Africa   \n",
       "217  C                    Tanzania   Eastern Africa   \n",
       "218  C                    Thailand        East Asia   \n",
       "139  C            Marshall Islands          Pacific   \n",
       "78   C                     Germany   Central Europe   \n",
       "156  C                       Nepal       South Asia   \n",
       "198  C             Solomon Islands          Pacific   \n",
       "141  C                   Mauritius   Eastern Africa   \n",
       "42   C                    Colombia    Latin America   \n",
       "47   C                     Curacao        Caribbean   \n",
       "\n",
       "                           Region 2  \n",
       "233           Europe & Central Asia  \n",
       "43      Africa Eastern and Southern  \n",
       "77            Europe & Central Asia  \n",
       "115           Europe & Central Asia  \n",
       "136                      South Asia  \n",
       "243      Middle East & North Africa  \n",
       "240             East Asia & Pacific  \n",
       "219       Latin America & Caribbean  \n",
       "19        Latin America & Caribbean  \n",
       "2        Africa Western and Central  \n",
       "118       Latin America & Caribbean  \n",
       "27              East Asia & Pacific  \n",
       "237           Europe & Central Asia  \n",
       "154     Africa Eastern and Southern  \n",
       "22                       South Asia  \n",
       "14       Middle East & North Africa  \n",
       "230     Africa Eastern and Southern  \n",
       "212      Middle East & North Africa  \n",
       "205                      South Asia  \n",
       "222      Africa Western and Central  \n",
       "199     Africa Eastern and Southern  \n",
       "217     Africa Eastern and Southern  \n",
       "218             East Asia & Pacific  \n",
       "139             East Asia & Pacific  \n",
       "78   Central Europe and the baltics  \n",
       "156                      South Asia  \n",
       "198             East Asia & Pacific  \n",
       "141     Africa Eastern and Southern  \n",
       "42        Latin America & Caribbean  \n",
       "47        Latin America & Caribbean  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "Create a dictionary to fill in the column 'Region 1' with singularly aggregated groups of countries\n",
    "'''\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Dictionary mapping African countries to regions\n",
    "africa_regions = {\n",
    "    # Northern Africa\n",
    "    \"Algeria\": \"Northern Africa\", \"Egypt\": \"Northern Africa\", \"Libya\": \"Northern Africa\", \"Morocco\": \"Northern Africa\", \"Sudan\": \"Northern Africa\", \"Tunisia\": \"Northern Africa\",\n",
    "    # Western Africa\n",
    "    \"Western Sahara\": \"Northern Africa\", \"Benin\": \"Western Africa\", \"Burkina Faso\": \"Western Africa\", \"Cape Verde\": \"Western Africa\", \"Ivory Coast\": \"Western Africa\",\n",
    "    \"The Gambia\": \"Western Africa\", \"Ghana\": \"Western Africa\", \"Guinea\": \"Western Africa\",  \"Guinea-Bissau\": \"Western Africa\", \"Liberia\": \"Western Africa\",  \"Mali\": \"Western Africa\",  \n",
    "    \"Mauritania\": \"Western Africa\", \"Niger\": \"Western Africa\",\"Nigeria\": \"Western Africa\", \"Senegal\": \"Western Africa\", \"Sierra Leone\": \"Western Africa\",  \"Togo\": \"Western Africa\", \n",
    "    'Cabo Verde': 'Western Africa',\n",
    "    # Central Africa\n",
    "    \"Angola\": \"Central Africa\",\"Cameroon\": \"Central Africa\", \"Central African Republic\": \"Central Africa\",  \"Chad\": \"Central Africa\", \"D.R. Congo\": \"Central Africa\",  \n",
    "    \"Congo\": \"Central Africa\", \"Equatorial Guinea\": \"Central Africa\", \"Gabon\": \"Central Africa\", \"Sao Tome and Principe\": \"Central Africa\", \n",
    "    # Eastern Africa\n",
    "    \"Burundi\": \"Eastern Africa\", \"Comoros\": \"Eastern Africa\", \"Djibouti\": \"Eastern Africa\", \"Eritrea\": \"Eastern Africa\", \"Ethiopia\": \"Eastern Africa\", \"Kenya\": \"Eastern Africa\", \n",
    "    \"Madagascar\": \"Eastern Africa\", \"Malawi\": \"Eastern Africa\",\"Mauritius\": \"Eastern Africa\", \"Mozambique\": \"Eastern Africa\",  \"Rwanda\": \"Eastern Africa\", \n",
    "    \"Seychelles\": \"Eastern Africa\", \"Somalia\": \"Eastern Africa\", \"South Sudan\": \"Eastern Africa\",\n",
    "    \"Tanzania\": \"Eastern Africa\",  \"Uganda\": \"Eastern Africa\", \"Zambia\": \"Eastern Africa\", \"Zimbabwe\": \"Eastern Africa\", \n",
    "    # Southern Africa\n",
    "    \"Botswana\": \"Southern Africa\", \"Eswatini\": \"Southern Africa\",\n",
    "    \"Lesotho\": \"Southern Africa\", \"Namibia\": \"Southern Africa\", \"South Africa\": \"Southern Africa\",\n",
    "    \n",
    "}\n",
    "\n",
    "europe_regions = {\n",
    "    # General Europe\n",
    "    'Albania': 'Europe', 'Andorra': 'Europe', 'Armenia': 'Europe', 'Austria': 'Europe', 'Azerbaijan': 'Europe',\n",
    "    'Belarus': 'Europe', 'Belgium': 'Europe', 'Bosnia and Herzegovina': 'Europe', 'Bulgaria': 'Europe',\n",
    "    'Croatia': 'Europe', 'Cyprus': 'Europe', 'Czech Republic': 'Europe', 'Denmark': 'Europe', 'Estonia': 'Europe',\n",
    "    'Finland': 'Europe', 'France': 'Europe', 'Georgia': 'Europe', 'Germany': 'Europe', 'Greece': 'Europe',\n",
    "    'Hungary': 'Europe', 'Iceland': 'Europe', 'Ireland': 'Europe', 'Italy': 'Europe', 'Kazakhstan': 'Europe',\n",
    "    'Kosovo': 'Europe', 'Latvia': 'Europe', 'Liechtenstein': 'Europe', 'Lithuania': 'Europe', 'Luxembourg': 'Europe',\n",
    "    'Malta': 'Europe', 'Moldova': 'Europe', 'Monaco': 'Europe', 'Montenegro': 'Europe', 'Netherlands': 'Europe',\n",
    "    'North Macedonia': 'Europe', 'Norway': 'Europe', 'Poland': 'Europe', 'Portugal': 'Europe', 'Romania': 'Europe',\n",
    "    'San Marino': 'Europe', 'Serbia': 'Europe', 'Slovakia': 'Europe', 'Slovenia': 'Europe', 'Spain': 'Europe',\n",
    "    'Sweden': 'Europe', 'Switzerland': 'Europe', 'Turkey': 'Europe', 'Ukraine': 'Europe', 'United Kingdom': 'Europe',\n",
    "    'Vatican City': 'Europe',\n",
    "    # Central Europe\n",
    "    'Austria': 'Central Europe', 'Czech Republic': 'Central Europe', 'Germany': 'Central Europe', 'Hungary': 'Central Europe', 'Russia': 'Central Europe',\n",
    "    'Liechtenstein': 'Central Europe', 'Poland': 'Central Europe', 'Slovak Republic': 'Central Europe', 'Switzerland': 'Central Europe',\n",
    "    # Baltics\n",
    "    'Estonia': 'Baltics', 'Latvia': 'Baltics', 'Lithuania': 'Baltics'\n",
    "}\n",
    "\n",
    "asia_regions = {\n",
    "    # Central Asia\n",
    "    'Afghanistan': 'Central Asia', 'Kazakhstan': 'Central Asia', 'Kyrgyzstan': 'Central Asia', 'Tajikistan': 'Central Asia', \n",
    "    'Turkmenistan': 'Central Asia', 'Uzbekistan': 'Central Asia',\n",
    "    # East Asia\n",
    "    'China': 'East Asia', 'Japan': 'East Asia', 'Mongolia': 'East Asia', 'North Korea': 'East Asia', 'South Korea': 'East Asia', 'Korea': 'East Asia','Thailand': 'East Asia',\n",
    "    'Viet Nam': 'East Asia', 'Indonesia': 'East Asia', 'Macao': 'East Asia', 'Hong Kong': 'East Asia', 'Malaysia': 'East Asia', 'Lao': 'East Asia',\n",
    "    'Timor-Leste': 'East Asia', 'Cambodia': 'East Asia', 'Brunei': 'East Asia', 'Myanmar':'East Asia','Singapore':'East Asia',\n",
    "    # South Asia\n",
    "    'Afghanistan': 'South Asia', 'Bangladesh': 'South Asia', 'Bhutan': 'South Asia', 'India': 'South Asia', 'Maldives': 'South Asia', \n",
    "    'Nepal': 'South Asia', 'Pakistan': 'South Asia', 'Sri Lanka': 'South Asia', \n",
    "    # Pacific\n",
    "    'Australia': 'Pacific', 'Fiji': 'Pacific', 'Kiribati': 'Pacific', 'Marshall Islands': 'Pacific', 'Micronesia': 'Pacific', 'Philippines': 'Pacific',\n",
    "    'Nauru': 'Pacific', 'New Zealand': 'Pacific', 'Palau': 'Pacific', 'Papua New Guinea': 'Pacific', 'Samoa': 'Pacific', \n",
    "    'Solomon Islands': 'Pacific', 'Tonga': 'Pacific', 'Tuvalu': 'Pacific', 'Vanuatu': 'Pacific'\n",
    "}\n",
    "\n",
    "middle_east_regions = {\n",
    "    # Middle East\n",
    "    'Afghanistan': 'Middle East', 'Bahrain': 'Middle East', 'Cyprus': 'Middle East', 'Egypt': 'Middle East', 'Iran': 'Middle East', \n",
    "    'Iraq': 'Middle East', 'Israel': 'Middle East', 'Jordan': 'Middle East', 'Kuwait': 'Middle East', 'Lebanon': 'Middle East', \n",
    "    'Oman': 'Middle East', 'Palestine': 'Middle East', 'Qatar': 'Middle East', 'Saudi Arabia': 'Middle East', 'Syria': 'Middle East', \n",
    "    'Turkiye': 'Middle East', 'United Arab Emirates': 'Middle East', 'Yemen': 'Middle East','West Bank and Gaza': 'Middle East'\n",
    "}\n",
    "\n",
    "americas_regions = {\n",
    "    # North America\n",
    "    'Canada': 'North America', 'Mexico': 'North America', 'United States': 'North America',\n",
    "    # Latin America (includes countries in South and Central America, and parts of the Caribbean)\n",
    "    'Argentina': 'Latin America', 'Belize': 'Latin America', 'Bolivia': 'Latin America', 'Brazil': 'Latin America', 'Chile': 'Latin America', \n",
    "    'Colombia': 'Latin America', 'Costa Rica': 'Latin America', 'Cuba': 'Latin America', 'Dominican Republic': 'Latin America', \n",
    "    'Ecuador': 'Latin America', 'El Salvador': 'Latin America', 'Guatemala': 'Latin America', 'Honduras': 'Latin America', \n",
    "    'Nicaragua': 'Latin America', 'Panama': 'Latin America', 'Paraguay': 'Latin America', 'Peru': 'Latin America', 'Uruguay': 'Latin America', \n",
    "    'Venezuela': 'Latin America', 'Suriname': 'Latin America', 'Guyana': 'Latin America',\n",
    "    # Caribbean\n",
    "    'Antigua and Barbuda': 'Caribbean', 'The Bahamas': 'Caribbean', 'Barbados': 'Caribbean', 'Cuba': 'Caribbean', 'Dominica': 'Caribbean', \n",
    "    'Grenada': 'Caribbean', 'Haiti': 'Caribbean', 'Jamaica': 'Caribbean', 'St. Kitts and Nevis': 'Caribbean', 'St. Lucia': 'Caribbean', \n",
    "    'St. Vincent and the Grenadines': 'Caribbean', 'Trinidad and Tobago': 'Caribbean', 'Aruba': 'Caribbean', 'Bermuda': 'Caribbean', \n",
    "    'Cayman Islands': 'Caribbean', 'Curacao': 'Caribbean', 'Montserrat': 'Caribbean', 'Puerto Rico': 'Caribbean', 'Saint BarthÃ©lemy': 'Caribbean',\n",
    "    'Saint Pierre and Miquelon': 'Caribbean', 'Anguilla': 'Caribbean', 'British Virgin Islands': 'Caribbean', 'Turks and Caicos Islands': 'Caribbean', \n",
    "    'Sint Maarten (Dutch part)': 'Caribbean'\n",
    "}\n",
    "\n",
    "not_applicable = {\n",
    "    'Africa Eastern and Southern': 'Not Applicable',\n",
    "    'Africa Western and Central': 'Not Applicable',\n",
    "    'Middle East & North Africa': 'Not Applicable',\n",
    "    'Central Europe and the baltics': 'Not Applicable',\n",
    "    'Europe & Central Asia': 'Not Applicable',\n",
    "    'East Asia & Pacific': 'Not Applicable',\n",
    "    'South Asia': 'Not Applicable',\n",
    "    'North America': 'Not Applicable',\n",
    "    'Latin America & Caribbean': 'Not Applicable'\n",
    "}\n",
    "\n",
    "# Function to assign region (singularly aggregated) based on country, leaving non-matching cells unchanged\n",
    "def assign_region1(b,c):\n",
    "    for i in range(len(b)):\n",
    "        country = b[i]\n",
    "        # Check if cell contains the country from dictionary\n",
    "        if country in africa_regions:\n",
    "            # Assign corresponding region to col c\n",
    "            c[i] = africa_regions[country]\n",
    "        elif country in europe_regions:\n",
    "            c[i] = europe_regions[country]\n",
    "        elif country in asia_regions:\n",
    "            c[i] = asia_regions[country]\n",
    "        elif country in middle_east_regions:\n",
    "            c[i] = middle_east_regions[country]\n",
    "        elif country in americas_regions:\n",
    "            c[i] = americas_regions[country]\n",
    "        elif country in not_applicable:\n",
    "            c[i] = not_applicable[country]\n",
    "            \n",
    "    return c\n",
    "\n",
    "df_names['Region 1'] = assign_region1(df_names['area'], df_names['Region 1'])\n",
    "\n",
    "'''\n",
    "Create a dictionary to fill in the column 'Region 2' with dually aggregated groups of countries\n",
    "'''\n",
    "un_regions = {\n",
    "    'Eastern Africa':'Africa Eastern and Southern',\n",
    "    'Southern Africa': 'Africa Eastern and Southern',\n",
    "    'Africa Eastern and Southern': 'Africa Eastern and Southern',\n",
    "    'Western Africa': 'Africa Western and Central',\n",
    "    'Central Africa': 'Africa Western and Central',\n",
    "    'Africa Western and Central': 'Africa Western and Central',\n",
    "    'Northern Africa': 'Middle East & North Africa',\n",
    "    'Middle East': 'Middle East & North Africa',\n",
    "    'Middle East & North Africa': 'Middle East & North Africa',\n",
    "    'Central Europe': 'Central Europe and the baltics',\n",
    "    'Baltics': 'Central Europe and the baltics',\n",
    "    'Central Europe and the baltics': 'Central Europe and the baltics',\n",
    "    'Europe': 'Europe & Central Asia',\n",
    "    'Central Asia': 'Europe & Central Asia',\n",
    "    'Europe & Central Asia': 'Europe & Central Asia',\n",
    "    'East Asia': 'East Asia & Pacific',\n",
    "    'Pacific': 'East Asia & Pacific',\n",
    "    'East Asia & Pacific': 'East Asia & Pacific',\n",
    "    'South Asia': 'South Asia',\n",
    "    'North America': 'North America',\n",
    "    'Latin America': 'Latin America & Caribbean',\n",
    "    'Caribbean': 'Latin America & Caribbean',\n",
    "    'Latin America & Caribbean': 'Latin America & Caribbean'\n",
    "}\n",
    "\n",
    "# Function to assign region (dually aggregated) based on singular region, leaving non-matching cells unchanged\n",
    "def assign_region2(b,c):\n",
    "    for i in range(len(b)):\n",
    "        region = b[i]\n",
    "        if region in un_regions:\n",
    "            c[i] = un_regions[region]\n",
    "    return c\n",
    "# Assign appropiate regional values to Region 2 column\n",
    "df_names['Region 2'] = assign_region2(df_names['Region 1'], df_names['Region 2'])\n",
    "df_names['Region 2'] = assign_region2(df_names['area'], df_names['Region 2'])\n",
    "#df_names[df_names['Region 2'].isna()].sample(n=30)\n",
    "\n",
    "# Drop non-inforative records\n",
    "df_names.dropna(subset=['Region 2'], inplace=True)\n",
    "print('Table 16 - Dataframe showing countries with their associated singular and UN specified regions')\n",
    "df_names.sample(n=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "09ddc599-0d32-4a4e-ab04-44fa5d107268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nuber of records in df_economy prior to dropping non-regional area categories : 5533\n",
      "Nuber of records in df_economy after dropping non-regional area categories : 4613\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4613 entries, 0 to 5532\n",
      "Data columns (total 24 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   country                      4613 non-null   object \n",
      " 1   region                       4613 non-null   object \n",
      " 2   un_region                    4613 non-null   object \n",
      " 3   year                         4613 non-null   int64  \n",
      " 4   gdp                          4613 non-null   float64\n",
      " 5   %pov                         1003 non-null   float64\n",
      " 6   cpia_regulation              1451 non-null   float64\n",
      " 7   cpia_gender                  1451 non-null   float64\n",
      " 8   cpia_resources               1451 non-null   float64\n",
      " 9   cpia_transparency            1451 non-null   float64\n",
      " 10  cpia_inclusion               1446 non-null   float64\n",
      " 11  cpia_trade                   1451 non-null   float64\n",
      " 12  healthcare$                  1025 non-null   float64\n",
      " 13  education$                   1468 non-null   float64\n",
      " 14  coll_enrollment              1948 non-null   float64\n",
      " 15  income_quintile2             1533 non-null   float64\n",
      " 16  income_quintile3             1533 non-null   float64\n",
      " 17  income_quintile4             1533 non-null   float64\n",
      " 18  income_quintile5             1533 non-null   float64\n",
      " 19  income_top10%                1533 non-null   float64\n",
      " 20  income_middle60%             1533 non-null   float64\n",
      " 21  income_difference_top-mid60  1533 non-null   float64\n",
      " 22  comm_import_capita           3020 non-null   float64\n",
      " 23  comm_export_capita           3020 non-null   float64\n",
      "dtypes: float64(20), int64(1), object(3)\n",
      "memory usage: 901.0+ KB\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "1. Create a dictionary where the associated df_names will become a dictionary to create a columns called 'single_region', 'un_region' in the master df_economy\n",
    "2. Create those new columns with associated regional values\n",
    "3. Drop records where the united nations region column is blank (columns are not regional or specified in a way that is not informative)\n",
    "'''\n",
    "singular_regions = dict(zip(df_names['area'], df_names['Region 1']))\n",
    "\n",
    "# Create function to read through country column and return asociated regional value from a dictionary\n",
    "def assign_single_region(b,c):\n",
    "    for i in range(len(b)):\n",
    "        country = b[i]\n",
    "        if country in singular_regions:\n",
    "            c[i] = singular_regions[country]\n",
    "    return c\n",
    "\n",
    "united_nations_regions = dict(zip(df_names['area'], df_names['Region 2']))\n",
    "\n",
    "# Create function to read through region column and return asociated UN specified regional value from a dictionary\n",
    "def assign_un_region(b,c):\n",
    "    for i in range(len(b)):\n",
    "        country = b[i]\n",
    "        if country in united_nations_regions:\n",
    "            c[i] = united_nations_regions[country]\n",
    "    return c\n",
    "\n",
    "# Initialize new columns with empty strings\n",
    "if 'region' not in df_economy:\n",
    "    df_economy['region'] = ''  \n",
    "if 'un_region' not in df_economy:\n",
    "    df_economy['un_region'] = ''\n",
    " \n",
    "# Create new regional columns using related user defined functions \n",
    "df_economy['region'] = assign_single_region(df_economy['area'], df_economy['region'])\n",
    "df_economy['un_region'] = assign_un_region(df_economy['area'], df_economy['un_region'])\n",
    "\n",
    "print(f'Nuber of records in df_economy prior to dropping non-regional area categories : {len(df_economy)}')\n",
    "\n",
    "# Replace empty strings with NaNs and drop records where UN related regions are NaNs\n",
    "df_economy.replace('', pd.NA, inplace=True)\n",
    "df_economy.dropna(subset=['un_region'], inplace=True)\n",
    "\n",
    "# Rename column 'area' to 'country' since region now has its own columns\n",
    "df_economy.rename(columns={'area': 'country'}, inplace=True)\n",
    "\n",
    "# Get column names\n",
    "columns = df_economy.columns.tolist()\n",
    "\n",
    "# Move the last two columns to the second and third position\n",
    "new_order = [columns[0]] +columns[-2:] + columns[1:-2]\n",
    "\n",
    "# Reorder the df per the new order\n",
    "df_economy = df_economy[new_order]\n",
    "\n",
    "print(f'Nuber of records in df_economy after dropping non-regional area categories : {len(df_economy)}')\n",
    "df_economy.to_csv('df_economy.csv', index=False)\n",
    "df_economy.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3189b3bd-dcf0-41b9-9e21-457fbfed8347",
   "metadata": {},
   "source": [
    "### 15. Assign regional level feature values to country level missing feature values if regional features present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6393899d-e9d1-4ae2-9e0d-f50d5983a0d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4429 entries, 0 to 5532\n",
      "Data columns (total 24 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   country                      4429 non-null   object \n",
      " 1   region                       4429 non-null   object \n",
      " 2   un_region                    4429 non-null   object \n",
      " 3   year                         4429 non-null   int64  \n",
      " 4   gdp                          4429 non-null   float64\n",
      " 5   %pov                         1003 non-null   float64\n",
      " 6   cpia_regulation              3229 non-null   float64\n",
      " 7   cpia_gender                  3229 non-null   float64\n",
      " 8   cpia_resources               3229 non-null   float64\n",
      " 9   cpia_transparency            3229 non-null   float64\n",
      " 10  cpia_inclusion               3229 non-null   float64\n",
      " 11  cpia_trade                   3229 non-null   float64\n",
      " 12  healthcare$                  1025 non-null   float64\n",
      " 13  education$                   1468 non-null   float64\n",
      " 14  coll_enrollment              1948 non-null   float64\n",
      " 15  income_quintile2             1533 non-null   float64\n",
      " 16  income_quintile3             1533 non-null   float64\n",
      " 17  income_quintile4             1533 non-null   float64\n",
      " 18  income_quintile5             1533 non-null   float64\n",
      " 19  income_top10%                1533 non-null   float64\n",
      " 20  income_middle60%             1533 non-null   float64\n",
      " 21  income_difference_top-mid60  1533 non-null   float64\n",
      " 22  comm_import_capita           3020 non-null   float64\n",
      " 23  comm_export_capita           3020 non-null   float64\n",
      "dtypes: float64(20), int64(1), object(3)\n",
      "memory usage: 865.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# Create a function to carry out assignment of regional level values to missing data in country level features\n",
    "def fill_from_region(df):\n",
    "    # Identify regional records\n",
    "    regional_rows = df[df['country'] == df['un_region']]\n",
    "    \n",
    "    # Create a dictionary with those records\n",
    "    regional_dict = regional_rows.set_index(['un_region', 'year']).to_dict(orient='index')\n",
    "    \n",
    "    # Create nested function to fill cells in row where cells are NaN\n",
    "    def fill_values(row):\n",
    "        region_year = (row['un_region'], row['year'])\n",
    "        \n",
    "        # Check to see if the region year pair exist in the regional data\n",
    "        if region_year in regional_dict:\n",
    "            for feature in ['cpia_regulation', 'cpia_gender', 'cpia_resources', 'cpia_transparency', 'cpia_inclusion', 'cpia_trade',\n",
    "                           'healthcare$', 'education$', 'coll_enrollment', 'income_quintile2', 'income_quintile3', 'income_quintile4', 'income_quintile5',\n",
    "                           'income_top10%', 'income_middle60%', 'income_difference_top-mid60', 'comm_import_capita', 'comm_export_capita']:\n",
    "                if pd.isna(row[feature]): # fill only if NaN\n",
    "                    row[feature] = regional_dict[region_year].get(feature, row[feature])\n",
    "        return row\n",
    "    # Apply function row-wise\n",
    "    df = df.apply(fill_values, axis=1)\n",
    "    \n",
    "    return df\n",
    "            \n",
    "    \n",
    "# Apply previous function to assign regional level feature values to missing country level feature values\n",
    "df_economy = fill_from_region(df_economy)\n",
    "\n",
    "# Drop all records where country equals un_region\n",
    "df_economy = df_economy[df_economy['country'] != df_economy['un_region']]\n",
    "df_economy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "60da1382-92de-4c9c-bf6d-3667f06e82c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_economy.to_csv('df_economy.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3588892-a7d0-416b-b1f7-887406c24a44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
